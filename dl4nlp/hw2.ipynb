{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers\n",
        "! pip install gdown\n",
        "! pip install torcheval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m4pbT5-SSre",
        "outputId": "678f697c-d753-4d0d-e4c8-67e45e69a5d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.6.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.11.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.6-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.4/158.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torcheval) (4.5.0)\n",
            "Collecting torchtnt>=0.0.5\n",
            "  Downloading torchtnt-0.0.7-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyre-extensions\n",
            "  Downloading pyre_extensions-0.0.30-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from torchtnt>=0.0.5->torcheval) (67.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from torchtnt>=0.0.5->torcheval) (2.0.0+cu118)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torchtnt>=0.0.5->torcheval) (2023.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from torchtnt>=0.0.5->torcheval) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.9/dist-packages (from torchtnt>=0.0.5->torcheval) (2.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtnt>=0.0.5->torcheval) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchtnt>=0.0.5->torcheval) (23.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtnt>=0.0.5->torcheval) (4.65.0)\n",
            "Collecting typing-inspect\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.53.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.2.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.9/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.20.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.40.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.27.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.4.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->torchtnt>=0.0.5->torcheval) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->torchtnt>=0.0.5->torcheval) (3.25.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (1.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard->torchtnt>=0.0.5->torcheval) (6.4.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard->torchtnt>=0.0.5->torcheval) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->torchtnt>=0.0.5->torcheval) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->torchtnt>=0.0.5->torcheval) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (3.2.2)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, pyre-extensions, torchtnt, torcheval\n",
            "Successfully installed mypy-extensions-1.0.0 pyre-extensions-0.0.30 torcheval-0.0.6 torchtnt-0.0.7 typing-inspect-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertConfig, BertTokenizerFast\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torcheval.metrics.functional import multiclass_f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "g0T0xu1gSjgl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "metadata": {
        "id": "GpXL6GK9d9ld"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1HgaaeoVTFptwIXth-mYfEaoWmoj_SHhX\n",
        "!gdown 19LzgUlM3417TlG6bmo-eSY5vRAKw2ukR\n",
        "!gdown 10eghJhKqJi-ZU6FoJrRS26CsuYBWFIuK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Lqq37IVSolX",
        "outputId": "57f1af75-8992-4163-bf2c-ed68686fbbff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HgaaeoVTFptwIXth-mYfEaoWmoj_SHhX\n",
            "To: /content/public_data.zip\n",
            "100% 92.1k/92.1k [00:00<00:00, 62.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19LzgUlM3417TlG6bmo-eSY5vRAKw2ukR\n",
            "To: /content/train_all.tsv\n",
            "100% 1.54M/1.54M [00:00<00:00, 126MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10eghJhKqJi-ZU6FoJrRS26CsuYBWFIuK\n",
            "To: /content/test-no_labels.tsv\n",
            "100% 298k/298k [00:00<00:00, 49.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z21o27DiesL",
        "outputId": "db378f39-3126-4bde-f94e-97dc94fc9eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  public_data.zip\n",
            "  inflating: val_empty.tsv           \n"
          ]
        }
      ],
      "source": [
        "!unzip public_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "s6uFknA3kg4m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('train_all.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "mGzhq6NQqiSU"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KnYWplrnq_5v",
        "outputId": "748756a9-b25f-4e7a-c50b-e0909f16e9fd"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      text_id                                               text  \\\n",
              "0       17024  [USER], согласно предписаниям Роспотребнадзора...   \n",
              "1       17025  О несоблюдении карантинных мер контактными лиц...   \n",
              "2       17027  [USER], читайте больше книжек на карантине, мо...   \n",
              "3       17030  Иди почитай инсту наших городских пабликов где...   \n",
              "4       17031  Все контактные лица, которых они обозначили, о...   \n",
              "...       ...                                                ...   \n",
              "6712    34033  [USER], меня больше заботят врачи, которые вын...   \n",
              "6713    34034  жрёт и жрёт вирус народ когда вакцина к нам пр...   \n",
              "6714    34035  Меня другой вопрос волнует, что ещё убьёт эта ...   \n",
              "6715    34037  А потом будут говорить про \"российскую медицин...   \n",
              "6716    34039  Вакцина не предотвращает заболевание, она прос...   \n",
              "\n",
              "      masks_stance  masks_argument  quarantine_stance  quarantine_argument  \\\n",
              "0               -1              -1                  1                    1   \n",
              "1               -1              -1                  1                    1   \n",
              "2               -1              -1                  1                    1   \n",
              "3               -1              -1                  1                    1   \n",
              "4               -1              -1                  1                    1   \n",
              "...            ...             ...                ...                  ...   \n",
              "6712            -1              -1                 -1                   -1   \n",
              "6713            -1              -1                 -1                   -1   \n",
              "6714            -1              -1                 -1                   -1   \n",
              "6715            -1              -1                 -1                   -1   \n",
              "6716            -1              -1                 -1                   -1   \n",
              "\n",
              "      vaccines_stance  vaccines_argument  \n",
              "0                  -1                 -1  \n",
              "1                  -1                 -1  \n",
              "2                  -1                 -1  \n",
              "3                  -1                 -1  \n",
              "4                  -1                 -1  \n",
              "...               ...                ...  \n",
              "6712                2                  1  \n",
              "6713                2                  1  \n",
              "6714                1                  1  \n",
              "6715                2                  1  \n",
              "6716                2                  2  \n",
              "\n",
              "[6717 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26d124e3-88ad-416c-9e74-76f3fc737f41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>text</th>\n",
              "      <th>masks_stance</th>\n",
              "      <th>masks_argument</th>\n",
              "      <th>quarantine_stance</th>\n",
              "      <th>quarantine_argument</th>\n",
              "      <th>vaccines_stance</th>\n",
              "      <th>vaccines_argument</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17024</td>\n",
              "      <td>[USER], согласно предписаниям Роспотребнадзора...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17025</td>\n",
              "      <td>О несоблюдении карантинных мер контактными лиц...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17027</td>\n",
              "      <td>[USER], читайте больше книжек на карантине, мо...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17030</td>\n",
              "      <td>Иди почитай инсту наших городских пабликов где...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17031</td>\n",
              "      <td>Все контактные лица, которых они обозначили, о...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6712</th>\n",
              "      <td>34033</td>\n",
              "      <td>[USER], меня больше заботят врачи, которые вын...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6713</th>\n",
              "      <td>34034</td>\n",
              "      <td>жрёт и жрёт вирус народ когда вакцина к нам пр...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6714</th>\n",
              "      <td>34035</td>\n",
              "      <td>Меня другой вопрос волнует, что ещё убьёт эта ...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6715</th>\n",
              "      <td>34037</td>\n",
              "      <td>А потом будут говорить про \"российскую медицин...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6716</th>\n",
              "      <td>34039</td>\n",
              "      <td>Вакцина не предотвращает заболевание, она прос...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6717 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26d124e3-88ad-416c-9e74-76f3fc737f41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26d124e3-88ad-416c-9e74-76f3fc737f41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26d124e3-88ad-416c-9e74-76f3fc737f41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_NAME = \"vaccines\" #\"quarantine\"  \"masks\""
      ],
      "metadata": {
        "id": "pJjIXDV7xuyx"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = 0\n",
        "length = []\n",
        "for text in data.text:\n",
        "    num += 1\n",
        "    length.append(len(text))\n",
        "print(np.median(length)), print(np.mean(length)), print(np.max(length)), print(np.min(length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXopXf8ZeHWX",
        "outputId": "e3dc37ff-609a-4a75-dee3-47c052a00c16"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92.0\n",
            "114.22897126693465\n",
            "2848\n",
            "25\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['text', f'{CLASS_NAME}_stance', f'{CLASS_NAME}_argument']]\n",
        "\n",
        "# Set your model output as categorical and save in new label col\n",
        "data['stance_label'] = pd.Categorical(data[f'{CLASS_NAME}_stance'])\n",
        "data['argument_label'] = pd.Categorical(data[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Transform your output to numeric\n",
        "data[f'{CLASS_NAME}_stance'] = data['stance_label'].cat.codes\n",
        "data[f'{CLASS_NAME}_argument'] = data['argument_label'].cat.codes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW-gOsXunkSG",
        "outputId": "ac74f38a-b02c-4888-88ad-9785addf641f"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-123-ec99ae5c8edc>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['stance_label'] = pd.Categorical(data[f'{CLASS_NAME}_stance'])\n",
            "<ipython-input-123-ec99ae5c8edc>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['argument_label'] = pd.Categorical(data[f'{CLASS_NAME}_argument'])\n",
            "<ipython-input-123-ec99ae5c8edc>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[f'{CLASS_NAME}_stance'] = data['stance_label'].cat.codes\n",
            "<ipython-input-123-ec99ae5c8edc>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data[f'{CLASS_NAME}_argument'] = data['argument_label'].cat.codes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "P6zkOdNiowkT",
        "outputId": "328d77aa-aa15-4544-ef10-d5e79ee6ee5f"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  vaccines_stance  \\\n",
              "0     [USER], согласно предписаниям Роспотребнадзора...                0   \n",
              "1     О несоблюдении карантинных мер контактными лиц...                0   \n",
              "2     [USER], читайте больше книжек на карантине, мо...                0   \n",
              "3     Иди почитай инсту наших городских пабликов где...                0   \n",
              "4     Все контактные лица, которых они обозначили, о...                0   \n",
              "...                                                 ...              ...   \n",
              "6712  [USER], меня больше заботят врачи, которые вын...                3   \n",
              "6713  жрёт и жрёт вирус народ когда вакцина к нам пр...                3   \n",
              "6714  Меня другой вопрос волнует, что ещё убьёт эта ...                2   \n",
              "6715  А потом будут говорить про \"российскую медицин...                3   \n",
              "6716  Вакцина не предотвращает заболевание, она прос...                3   \n",
              "\n",
              "      vaccines_argument stance_label argument_label  \n",
              "0                     0           -1             -1  \n",
              "1                     0           -1             -1  \n",
              "2                     0           -1             -1  \n",
              "3                     0           -1             -1  \n",
              "4                     0           -1             -1  \n",
              "...                 ...          ...            ...  \n",
              "6712                  2            2              1  \n",
              "6713                  2            2              1  \n",
              "6714                  2            1              1  \n",
              "6715                  2            2              1  \n",
              "6716                  3            2              2  \n",
              "\n",
              "[6717 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-910af299-7750-4e3c-b191-c2bc5f75a11b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>vaccines_stance</th>\n",
              "      <th>vaccines_argument</th>\n",
              "      <th>stance_label</th>\n",
              "      <th>argument_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[USER], согласно предписаниям Роспотребнадзора...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>О несоблюдении карантинных мер контактными лиц...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[USER], читайте больше книжек на карантине, мо...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Иди почитай инсту наших городских пабликов где...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Все контактные лица, которых они обозначили, о...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6712</th>\n",
              "      <td>[USER], меня больше заботят врачи, которые вын...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6713</th>\n",
              "      <td>жрёт и жрёт вирус народ когда вакцина к нам пр...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6714</th>\n",
              "      <td>Меня другой вопрос волнует, что ещё убьёт эта ...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6715</th>\n",
              "      <td>А потом будут говорить про \"российскую медицин...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6716</th>\n",
              "      <td>Вакцина не предотвращает заболевание, она прос...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6717 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-910af299-7750-4e3c-b191-c2bc5f75a11b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-910af299-7750-4e3c-b191-c2bc5f75a11b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-910af299-7750-4e3c-b191-c2bc5f75a11b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = train_test_split(data, test_size=0.15)"
      ],
      "metadata": {
        "id": "rZd8OaR6nlEI"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'DeepPavlov/rubert-base-cased-sentence'\n",
        "\n",
        "# Load transformers config and set output_hidden_states to False\n",
        "config = BertConfig.from_pretrained(model_name)\n",
        "config.output_hidden_states = False\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config=config)\n",
        "\n",
        "# Load the Transformers BERT model\n",
        "transformer_model = BertModel.from_pretrained(model_name, config=config)\n",
        "\n",
        "# Load the MainLayer\n",
        "# bert = transformer_model.layers[0]"
      ],
      "metadata": {
        "id": "8FCPIWHkoA5v"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def target_to_torch(target):\n",
        "    return torch.tensor(target.to_numpy()).to(torch.long)\n",
        "  \n",
        "def tokenize(text):\n",
        "    return tokenizer(\n",
        "    text=text,\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding='max_length', \n",
        "    return_tensors='pt',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = False,\n",
        "    verbose = True)"
      ],
      "metadata": {
        "id": "2uGF96w8q9p_"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_y_stance = target_to_torch(val[f'{CLASS_NAME}_stance'])\n",
        "val_y_argument = target_to_torch(val[f'{CLASS_NAME}_argument'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "val_x = tokenize(val['text'].to_list())"
      ],
      "metadata": {
        "id": "8VscxTs2nwbD"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_stance = torch.tensor(train[f'{CLASS_NAME}_stance'].to_numpy()).to(torch.long)\n",
        "y_argument = torch.tensor(train[f'{CLASS_NAME}_argument'].to_numpy()).to(torch.long)\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenize(train['text'].to_list())"
      ],
      "metadata": {
        "id": "_AsUvx4ooJej"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVm-ZkCqXKFQ",
        "outputId": "3a4fa091-1e6e-4865-9af6-954581910477"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, bert):\n",
        "        super().__init__()\n",
        "        self.bert = bert\n",
        "        self.linear1 = nn.Sequential(nn.Linear(in_features=768, out_features=768, bias=True), \n",
        "                                    nn.Dropout(0.1), nn.ReLU(), \n",
        "                                    nn.Linear(in_features=768, out_features=4, bias=True))\n",
        "        self.linear2 = nn.Sequential(nn.Linear(in_features=768, out_features=768, bias=True), \n",
        "                            nn.Dropout(0.1), nn.ReLU(), \n",
        "                            nn.Linear(in_features=768, out_features=4, bias=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.bert(x)[1]\n",
        "        out1 = self.linear1(out)\n",
        "        out2 = self.linear2(out)\n",
        "        return out1, out2"
      ],
      "metadata": {
        "id": "kvwf6E9bMnMM"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels_stance, labels_argument):\n",
        "        self.data = data\n",
        "        self.labels_stance = labels_stance\n",
        "        self.labels_argument = labels_argument\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.data[idx]\n",
        "        label_stance = self.labels_stance[idx]\n",
        "        label_argument = self.labels_argument[idx]\n",
        "        return sentence, label_stance, label_argument"
      ],
      "metadata": {
        "id": "Jsu7_0tddrzR"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epochs_num = 10\n",
        "learning_rate = 5e-5"
      ],
      "metadata": {
        "id": "B3SjOyYK1gXN"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(x['input_ids'], y_stance, y_argument)\n",
        "val_dataset = CustomDataset(val_x['input_ids'], val_y_stance, val_y_argument)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)#, drop_last=False)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)#, drop_last=True)"
      ],
      "metadata": {
        "id": "2CA4rGCTe8Ry"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "WodaE8tM3A5O"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(transformer_model)\n",
        "model.to(device)\n",
        "for param in model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01, amsgrad=False)"
      ],
      "metadata": {
        "id": "UXVHA_B17eDP"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "pIJozt-GjuXf"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index, dataset):\n",
        "    running_loss = 0.\n",
        "    running_accuracy = 0.\n",
        "    stance_acc_total = 0.0\n",
        "    argument_acc_total = 0.0\n",
        "\n",
        "    obj_size = 0\n",
        "    for i, data in enumerate(dataset):\n",
        "        inputs, labels_stance, labels_argument = data\n",
        "        output1, output2 = model(inputs.to(device))\n",
        "        obj_size += len(inputs)\n",
        "        \n",
        "        stance_predict = torch.argmax(output1.cpu(), dim=1)\n",
        "        argument_predict = torch.argmax(output2.cpu(), dim=1)\n",
        "        stance_acc_total += (labels_stance == stance_predict).sum().item()\n",
        "        argument_acc_total += (labels_argument == argument_predict).sum().item()\n",
        "\n",
        "        loss1 = loss_fn(output1.cpu(), labels_stance)\n",
        "        loss2 = loss_fn(output2.cpu(), labels_argument)\n",
        "        loss = loss1 + loss2\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if not i % 100:\n",
        "            print(f'current loss: {np.round(running_loss / obj_size, 4)}')\n",
        "            print('stance_loss:', np.round(loss1.item(), 4), \n",
        "                  'argument_loss:', np.round(loss2.item(), 4), end=' ')\n",
        "            print('stance_acc:', np.round(stance_acc_total / obj_size, 4), \n",
        "                  'argument_acc:', np.round(argument_acc_total / obj_size, 4))\n",
        "\n",
        "    return running_loss / obj_size, stance_acc_total / obj_size, argument_acc_total / obj_size\n",
        "\n",
        "\n",
        "def val_one_epoch(epoch_index, dataset):\n",
        "    running_loss = 0.\n",
        "    running_accuracy = 0.\n",
        "    stance_acc_total = 0.0\n",
        "    argument_acc_total = 0.0\n",
        "\n",
        "    stance_pred = []\n",
        "    arg_pred = []\n",
        "    obj_size = 0\n",
        "    for i, data in enumerate(dataset):\n",
        "        inputs, labels_stance, labels_argument = data\n",
        "        output1, output2 = model(inputs.to(device))\n",
        "        obj_size += len(inputs)\n",
        "\n",
        "        stance_predict = torch.argmax(output1.cpu(), dim=1)\n",
        "        stance_pred.append(stance_predict)\n",
        "        argument_predict = torch.argmax(output2.cpu(), dim=1)\n",
        "        arg_pred.append(argument_predict)\n",
        "\n",
        "        stance_acc_total += (labels_stance == stance_predict).sum().item()\n",
        "        argument_acc_total += (labels_argument == argument_predict).sum().item()\n",
        "\n",
        "        loss1 = loss_fn(output1.cpu(), labels_stance).item()\n",
        "        loss2 = loss_fn(output2.cpu(), labels_argument).item()\n",
        "        loss = loss1 + loss2\n",
        "\n",
        "        running_loss += loss\n",
        "        if not i % 100:\n",
        "            print(f'current loss: {np.round(running_loss / obj_size, 4)}')\n",
        "            print('stance_loss:', np.round(loss1, 4), \n",
        "                  'argument_loss:', np.round(loss2, 4), end=' ')\n",
        "            print('stance_acc:', np.round(stance_acc_total / obj_size, 4), \n",
        "                  'argument_acc:', np.round(argument_acc_total / obj_size, 4))\n",
        "\n",
        "    return running_loss / obj_size, stance_pred, arg_pred"
      ],
      "metadata": {
        "id": "rePZZvkkitGe"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_vstance = 0\n",
        "best_varg = 0\n",
        "\n",
        "for epoch in range(epochs_num):\n",
        "    print()\n",
        "    print(f'EPOCH {epoch+1}')\n",
        "    model.train()\n",
        "    avg_loss, stance_acc, arg_acc = train_one_epoch(epoch, train_dataloader)\n",
        "    print(f'----------------TRAIN LOSS on epoch {epoch+1}:', np.round(avg_loss, 4))\n",
        "    print('TRAIN stance acc:', np.round(stance_acc, 4), 'arg acc:', np.round(arg_acc, 4))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        avg_vloss, stance_pred, arg_pred = val_one_epoch(epoch, val_dataloader)\n",
        "    stance_pred = torch.cat(stance_pred, dim=0)\n",
        "    arg_pred = torch.cat(arg_pred, dim=0)\n",
        "    stance_f1 = multiclass_f1_score(stance_pred[val_y_stance!=0], val_y_stance[val_y_stance!=0], \n",
        "                                    num_classes=4, average=\"macro\").item()\n",
        "    arg_f1 = multiclass_f1_score(arg_pred[val_y_argument!=0], val_y_argument[val_y_argument!=0], \n",
        "                                 num_classes=4, average=\"macro\").item()\n",
        "\n",
        "    print(f'----------------VAL LOSS on epoch {epoch+1}:', np.round(avg_vloss, 4))\n",
        "\n",
        "    if np.isclose(best_vstance, stance_f1, 1e-4) and (best_varg < arg_f1):\n",
        "        best_vstance = stance_f1\n",
        "        best_varg = arg_f1\n",
        "        model_path = 'model_{}'.format(epoch+1)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f'best results: best f1_stance = {best_vstance}, best_f1_arg = {best_varg}')\n",
        "    elif best_vstance < stance_f1:\n",
        "        best_vstance = stance_f1\n",
        "        best_varg = arg_f1\n",
        "        model_path = 'model_{}'.format(epoch+1)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f'best results: best f1_stance = {best_vstance}, best_f1_arg = {best_varg}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knOYQXewiEb9",
        "outputId": "7fd12650-7789-41bf-b2ca-ebf37255f272"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH 1\n",
            "current loss: 0.1754\n",
            "stance_loss: 1.3847 argument_loss: 1.4219 stance_acc: 0.25 argument_acc: 0.375\n",
            "current loss: 0.1121\n",
            "stance_loss: 0.8208 argument_loss: 0.8421 stance_acc: 0.7364 argument_acc: 0.7296\n",
            "current loss: 0.1054\n",
            "stance_loss: 0.6639 argument_loss: 0.5355 stance_acc: 0.7404 argument_acc: 0.7369\n",
            "current loss: 0.1013\n",
            "stance_loss: 0.9079 argument_loss: 0.9566 stance_acc: 0.7479 argument_acc: 0.7456\n",
            "----------------TRAIN LOSS on epoch 1: 0.0997\n",
            "TRAIN stance acc: 0.7514 arg acc: 0.7495\n",
            "current loss: 0.1501\n",
            "stance_loss: 1.227 argument_loss: 1.1746 stance_acc: 0.5625 argument_acc: 0.5625\n",
            "----------------VAL LOSS on epoch 1: 0.0949\n",
            "best results: best f1_stance = 0.21347357332706451, best_f1_arg = 0.21347357332706451\n",
            "\n",
            "EPOCH 2\n",
            "current loss: 0.0712\n",
            "stance_loss: 0.6348 argument_loss: 0.504 stance_acc: 0.8125 argument_acc: 0.8125\n",
            "current loss: 0.0961\n",
            "stance_loss: 0.291 argument_loss: 0.2874 stance_acc: 0.7512 argument_acc: 0.7512\n",
            "current loss: 0.0946\n",
            "stance_loss: 0.6475 argument_loss: 0.7016 stance_acc: 0.7509 argument_acc: 0.7509\n",
            "current loss: 0.0934\n",
            "stance_loss: 1.1329 argument_loss: 1.001 stance_acc: 0.7546 argument_acc: 0.7546\n",
            "----------------TRAIN LOSS on epoch 2: 0.0931\n",
            "TRAIN stance acc: 0.7546 arg acc: 0.7546\n",
            "current loss: 0.1412\n",
            "stance_loss: 1.1437 argument_loss: 1.116 stance_acc: 0.5625 argument_acc: 0.5625\n",
            "----------------VAL LOSS on epoch 2: 0.0893\n",
            "best results: best f1_stance = 0.21347357332706451, best_f1_arg = 0.21614600718021393\n",
            "\n",
            "EPOCH 3\n",
            "current loss: 0.0769\n",
            "stance_loss: 0.5436 argument_loss: 0.6864 stance_acc: 0.875 argument_acc: 0.875\n",
            "current loss: 0.0935\n",
            "stance_loss: 0.6846 argument_loss: 0.4658 stance_acc: 0.7488 argument_acc: 0.7488\n",
            "current loss: 0.0907\n",
            "stance_loss: 0.7772 argument_loss: 0.7364 stance_acc: 0.7528 argument_acc: 0.7531\n",
            "current loss: 0.0893\n",
            "stance_loss: 0.6677 argument_loss: 0.5189 stance_acc: 0.7569 argument_acc: 0.7573\n",
            "----------------TRAIN LOSS on epoch 3: 0.0899\n",
            "TRAIN stance acc: 0.7546 arg acc: 0.7553\n",
            "current loss: 0.1262\n",
            "stance_loss: 1.0305 argument_loss: 0.9894 stance_acc: 0.5625 argument_acc: 0.5625\n",
            "----------------VAL LOSS on epoch 3: 0.0838\n",
            "best results: best f1_stance = 0.22482967376708984, best_f1_arg = 0.2702217102050781\n",
            "\n",
            "EPOCH 4\n",
            "current loss: 0.0601\n",
            "stance_loss: 0.5325 argument_loss: 0.4293 stance_acc: 0.875 argument_acc: 0.875\n",
            "current loss: 0.0876\n",
            "stance_loss: 0.6781 argument_loss: 0.5972 stance_acc: 0.7506 argument_acc: 0.7574\n",
            "current loss: 0.0865\n",
            "stance_loss: 1.3578 argument_loss: 1.4756 stance_acc: 0.7553 argument_acc: 0.7621\n",
            "current loss: 0.087\n",
            "stance_loss: 0.6202 argument_loss: 0.633 stance_acc: 0.7537 argument_acc: 0.7623\n",
            "----------------TRAIN LOSS on epoch 4: 0.087\n",
            "TRAIN stance acc: 0.7553 arg acc: 0.763\n",
            "current loss: 0.1189\n",
            "stance_loss: 0.9744 argument_loss: 0.9284 stance_acc: 0.5625 argument_acc: 0.625\n",
            "----------------VAL LOSS on epoch 4: 0.0794\n",
            "best results: best f1_stance = 0.26677125692367554, best_f1_arg = 0.3214842677116394\n",
            "\n",
            "EPOCH 5\n",
            "current loss: 0.0796\n",
            "stance_loss: 0.6595 argument_loss: 0.6133 stance_acc: 0.8125 argument_acc: 0.8125\n",
            "current loss: 0.0859\n",
            "stance_loss: 1.0492 argument_loss: 1.1748 stance_acc: 0.7537 argument_acc: 0.7704\n",
            "current loss: 0.0857\n",
            "stance_loss: 0.5094 argument_loss: 0.6558 stance_acc: 0.7525 argument_acc: 0.7705\n",
            "current loss: 0.0842\n",
            "stance_loss: 0.9211 argument_loss: 0.8081 stance_acc: 0.7589 argument_acc: 0.7768\n",
            "----------------TRAIN LOSS on epoch 5: 0.0844\n",
            "TRAIN stance acc: 0.7586 arg acc: 0.7761\n",
            "current loss: 0.1133\n",
            "stance_loss: 0.919 argument_loss: 0.8936 stance_acc: 0.625 argument_acc: 0.6875\n",
            "----------------VAL LOSS on epoch 5: 0.0751\n",
            "best results: best f1_stance = 0.31791695952415466, best_f1_arg = 0.359591007232666\n",
            "\n",
            "EPOCH 6\n",
            "current loss: 0.0788\n",
            "stance_loss: 0.7192 argument_loss: 0.5417 stance_acc: 0.8125 argument_acc: 0.8125\n",
            "current loss: 0.078\n",
            "stance_loss: 0.4406 argument_loss: 0.4986 stance_acc: 0.7797 argument_acc: 0.7884\n",
            "current loss: 0.0812\n",
            "stance_loss: 0.1735 argument_loss: 0.179 stance_acc: 0.7668 argument_acc: 0.7808\n",
            "current loss: 0.0813\n",
            "stance_loss: 0.8428 argument_loss: 0.7991 stance_acc: 0.7664 argument_acc: 0.7816\n",
            "----------------TRAIN LOSS on epoch 6: 0.0821\n",
            "TRAIN stance acc: 0.7644 arg acc: 0.781\n",
            "current loss: 0.1051\n",
            "stance_loss: 0.8404 argument_loss: 0.8414 stance_acc: 0.6875 argument_acc: 0.75\n",
            "----------------VAL LOSS on epoch 6: 0.0725\n",
            "best results: best f1_stance = 0.35734522342681885, best_f1_arg = 0.3898687958717346\n",
            "\n",
            "EPOCH 7\n",
            "current loss: 0.0684\n",
            "stance_loss: 0.568 argument_loss: 0.5258 stance_acc: 0.875 argument_acc: 0.9375\n",
            "current loss: 0.0809\n",
            "stance_loss: 0.5079 argument_loss: 0.3841 stance_acc: 0.7661 argument_acc: 0.7939\n",
            "current loss: 0.0804\n",
            "stance_loss: 0.6846 argument_loss: 0.5695 stance_acc: 0.7683 argument_acc: 0.7954\n",
            "current loss: 0.0801\n",
            "stance_loss: 0.5074 argument_loss: 0.3428 stance_acc: 0.7697 argument_acc: 0.7949\n",
            "----------------TRAIN LOSS on epoch 7: 0.0795\n",
            "TRAIN stance acc: 0.7712 arg acc: 0.7952\n",
            "current loss: 0.1032\n",
            "stance_loss: 0.831 argument_loss: 0.8207 stance_acc: 0.6875 argument_acc: 0.75\n",
            "----------------VAL LOSS on epoch 7: 0.0696\n",
            "best results: best f1_stance = 0.36480528116226196, best_f1_arg = 0.39379507303237915\n",
            "\n",
            "EPOCH 8\n",
            "current loss: 0.075\n",
            "stance_loss: 0.6352 argument_loss: 0.5656 stance_acc: 0.8125 argument_acc: 0.8125\n",
            "current loss: 0.0779\n",
            "stance_loss: 0.5133 argument_loss: 0.3814 stance_acc: 0.784 argument_acc: 0.7976\n",
            "current loss: 0.0773\n",
            "stance_loss: 0.3287 argument_loss: 0.2703 stance_acc: 0.7792 argument_acc: 0.7985\n",
            "current loss: 0.0778\n",
            "stance_loss: 0.444 argument_loss: 0.3643 stance_acc: 0.778 argument_acc: 0.7982\n",
            "----------------TRAIN LOSS on epoch 8: 0.0781\n",
            "TRAIN stance acc: 0.777 arg acc: 0.7977\n",
            "current loss: 0.0987\n",
            "stance_loss: 0.7915 argument_loss: 0.7884 stance_acc: 0.6875 argument_acc: 0.75\n",
            "----------------VAL LOSS on epoch 8: 0.0668\n",
            "best results: best f1_stance = 0.3661273717880249, best_f1_arg = 0.3942975401878357\n",
            "\n",
            "EPOCH 9\n",
            "current loss: 0.0248\n",
            "stance_loss: 0.2133 argument_loss: 0.1831 stance_acc: 1.0 argument_acc: 1.0\n",
            "current loss: 0.0723\n",
            "stance_loss: 0.8758 argument_loss: 0.8296 stance_acc: 0.7952 argument_acc: 0.8212\n",
            "current loss: 0.0757\n",
            "stance_loss: 0.5313 argument_loss: 0.4049 stance_acc: 0.7854 argument_acc: 0.8116\n",
            "current loss: 0.0758\n",
            "stance_loss: 0.8915 argument_loss: 0.7747 stance_acc: 0.7832 argument_acc: 0.8094\n",
            "----------------TRAIN LOSS on epoch 9: 0.0756\n",
            "TRAIN stance acc: 0.7828 arg acc: 0.8085\n",
            "current loss: 0.0969\n",
            "stance_loss: 0.7711 argument_loss: 0.7795 stance_acc: 0.75 argument_acc: 0.75\n",
            "----------------VAL LOSS on epoch 9: 0.0653\n",
            "best results: best f1_stance = 0.37715697288513184, best_f1_arg = 0.4009496569633484\n",
            "\n",
            "EPOCH 10\n",
            "current loss: 0.0487\n",
            "stance_loss: 0.4128 argument_loss: 0.3669 stance_acc: 0.875 argument_acc: 0.875\n",
            "current loss: 0.0765\n",
            "stance_loss: 0.4825 argument_loss: 0.4942 stance_acc: 0.7803 argument_acc: 0.8051\n",
            "current loss: 0.0759\n",
            "stance_loss: 0.3125 argument_loss: 0.2979 stance_acc: 0.7811 argument_acc: 0.8041\n",
            "current loss: 0.0753\n",
            "stance_loss: 0.9945 argument_loss: 0.7613 stance_acc: 0.7832 argument_acc: 0.8077\n",
            "----------------TRAIN LOSS on epoch 10: 0.075\n",
            "TRAIN stance acc: 0.7835 arg acc: 0.8091\n",
            "current loss: 0.0947\n",
            "stance_loss: 0.7473 argument_loss: 0.7681 stance_acc: 0.75 argument_acc: 0.75\n",
            "----------------VAL LOSS on epoch 10: 0.0642\n",
            "best results: best f1_stance = 0.3793219327926636, best_f1_arg = 0.4048398733139038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "yNpLQNEBiEeg"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_vstance = 0\n",
        "best_varg = 0\n",
        "epochs_num = 6\n",
        "\n",
        "for epoch in range(epochs_num):\n",
        "    print()\n",
        "    print(f'EPOCH {epoch+1}')\n",
        "    model.train()\n",
        "    avg_loss, stance_acc, arg_acc = train_one_epoch(epoch, train_dataloader)\n",
        "    print(f'----------------TRAIN LOSS on epoch {epoch+1}:', np.round(avg_loss, 4))\n",
        "    print('TRAIN stance acc:', np.round(stance_acc, 4), 'arg acc:', np.round(arg_acc, 4))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        avg_vloss, stance_pred, arg_pred = val_one_epoch(epoch, val_dataloader)\n",
        "    stance_pred = torch.cat(stance_pred, dim=0)\n",
        "    arg_pred = torch.cat(arg_pred, dim=0)\n",
        "    stance_f1 = multiclass_f1_score(stance_pred[val_y_stance!=0], val_y_stance[val_y_stance!=0], \n",
        "                                    num_classes=4, average=\"macro\").item()\n",
        "    arg_f1 = multiclass_f1_score(arg_pred[val_y_argument!=0], val_y_argument[val_y_argument!=0], \n",
        "                                 num_classes=4, average=\"macro\").item()\n",
        "\n",
        "    print(f'----------------VAL LOSS on epoch {epoch+1}:', np.round(avg_vloss, 4))\n",
        "\n",
        "    if np.isclose(best_vstance, stance_f1, 1e-4) and (best_varg < arg_f1):\n",
        "        best_vstance = stance_f1\n",
        "        best_varg = arg_f1\n",
        "        model_path = 'model_{}'.format(epoch+1)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f'best results: best f1_stance = {best_vstance}, best_f1_arg = {best_varg}')\n",
        "    elif best_vstance < stance_f1:\n",
        "        best_vstance = stance_f1\n",
        "        best_varg = arg_f1\n",
        "        model_path = 'model_{}'.format(epoch+1)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f'best results: best f1_stance = {best_vstance}, best_f1_arg = {best_varg}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BKMABccviEhO",
        "outputId": "36746f58-9ec3-488b-823d-be73f82fc432"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH 1\n",
            "current loss: 0.018\n",
            "stance_loss: 0.1671 argument_loss: 0.1209 stance_acc: 0.875 argument_acc: 0.9375\n",
            "current loss: 0.0252\n",
            "stance_loss: 0.398 argument_loss: 0.0331 stance_acc: 0.9016 argument_acc: 0.9431\n",
            "current loss: 0.0258\n",
            "stance_loss: 0.2151 argument_loss: 0.2188 stance_acc: 0.8918 argument_acc: 0.9397\n",
            "current loss: 0.0263\n",
            "stance_loss: 0.3145 argument_loss: 0.1945 stance_acc: 0.8864 argument_acc: 0.9363\n",
            "----------------TRAIN LOSS on epoch 1: 0.0265\n",
            "TRAIN stance acc: 0.8861 arg acc: 0.9345\n",
            "current loss: 0.0459\n",
            "stance_loss: 0.41 argument_loss: 0.3246 stance_acc: 0.75 argument_acc: 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------VAL LOSS on epoch 1: 0.0272\n",
            "best results: best f1_stance = 0.30022522807121277, best_f1_arg = 0.2321428656578064\n",
            "\n",
            "EPOCH 2\n",
            "current loss: 0.0046\n",
            "stance_loss: 0.0516 argument_loss: 0.0214 stance_acc: 1.0 argument_acc: 1.0\n",
            "current loss: 0.0236\n",
            "stance_loss: 0.5297 argument_loss: 0.1352 stance_acc: 0.9053 argument_acc: 0.9375\n",
            "current loss: 0.0233\n",
            "stance_loss: 0.4032 argument_loss: 0.4717 stance_acc: 0.9058 argument_acc: 0.9412\n",
            "current loss: 0.0231\n",
            "stance_loss: 0.211 argument_loss: 0.129 stance_acc: 0.9103 argument_acc: 0.9421\n",
            "----------------TRAIN LOSS on epoch 2: 0.0228\n",
            "TRAIN stance acc: 0.9117 arg acc: 0.9425\n",
            "current loss: 0.0471\n",
            "stance_loss: 0.3633 argument_loss: 0.3899 stance_acc: 0.8125 argument_acc: 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n",
            "WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------VAL LOSS on epoch 2: 0.027\n",
            "best results: best f1_stance = 0.3628914952278137, best_f1_arg = 0.22871343791484833\n",
            "\n",
            "EPOCH 3\n",
            "current loss: 0.0184\n",
            "stance_loss: 0.1513 argument_loss: 0.1434 stance_acc: 0.9375 argument_acc: 0.9375\n",
            "current loss: 0.0166\n",
            "stance_loss: 0.2272 argument_loss: 0.0671 stance_acc: 0.9394 argument_acc: 0.9616\n",
            "current loss: 0.0167\n",
            "stance_loss: 0.0777 argument_loss: 0.047 stance_acc: 0.94 argument_acc: 0.9574\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-142-ff0210bedcb7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'EPOCH {epoch+1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstance_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'----------------TRAIN LOSS on epoch {epoch+1}:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TRAIN stance acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstance_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'arg acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-138-91fae3e5cfe9>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch_index, dataset)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mobj_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mstance_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0margument_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mstance_acc_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels_stance\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstance_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_predict(model, data):\n",
        "    stances = []\n",
        "    args = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(test_x['input_ids']), batch_size):\n",
        "            out1, out2 = model(data[i:i+batch_size])\n",
        "            stances.append(torch.argmax(out1.cpu(), dim=-1))\n",
        "            args.append(torch.argmax(out2.cpu(), dim=-1))\n",
        "    return stances, args"
      ],
      "metadata": {
        "id": "wLZV0l4TReKn"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('test-no_labels.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "OloSoNxxiEj1"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = tokenize(test['text'].to_list())"
      ],
      "metadata": {
        "id": "PaS9-c5hPTFi"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stances, args = model_predict(model, test_x['input_ids'].to(device))"
      ],
      "metadata": {
        "id": "N1Xyyj4rPTRD"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stances = torch.cat(stances, dim=0)\n",
        "args = torch.cat(args, dim=0)"
      ],
      "metadata": {
        "id": "6z1EX8VCQl9V"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[f'{CLASS_NAME}_stance_predict'] = stances\n",
        "test[f'{CLASS_NAME}_argument_predict'] = args\n",
        "test[f'{CLASS_NAME}_stance_predict'] -= 1\n",
        "test[f'{CLASS_NAME}_argument_predict'] -= 1"
      ],
      "metadata": {
        "id": "Dsz7t17dT2UU"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[['text', f'{CLASS_NAME}_stance_predict', f'{CLASS_NAME}_argument_predict']].to_csv(f\"test_predict_{CLASS_NAME}.tsv\", sep='\\t', index=None)"
      ],
      "metadata": {
        "id": "bU_rSjneUiTz"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", \n",
        "    learning_rate=6e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=epochs_num,\n",
        "    weight_decay=0.01,\n",
        "    adam_epsilon=1e-08,\n",
        "    max_grad_norm=1.0,\n",
        "    warmup_ratio=0.0,\n",
        "    save_strategy='no',\n",
        "    report_to='none',)"
      ],
      "metadata": {
        "id": "2QxeRyjk-y7V"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from datasets import load_dataset, load_metric\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"seqeval\")"
      ],
      "metadata": {
        "id": "AqnOP101_DSl"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    predictions, labels = p.predictions, p.label_ids\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    results = metric.compute(predictions=predictions, references=labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "eGR4VCQT_FRp"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nFqFYvP4U9bM"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(torch.tensor([[101, 13001, 10636, 10783, 166, 102]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtYIWnRjV2sZ",
        "outputId": "29f7e052-e731-4de8-965c-169996b30114"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3672,  0.0743,  0.1122, -0.2410],\n",
              "         [-0.3672,  0.0594,  0.1683, -0.2139],\n",
              "         [-0.3998,  0.0879,  0.0840, -0.2644],\n",
              "         [-0.3471,  0.0596,  0.0118, -0.1929],\n",
              "         [-0.3169,  0.0183,  0.1473, -0.3025],\n",
              "         [-0.3318,  0.0742,  0.1135, -0.2131]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=x,#tokenized_datasets[\"train\"],\n",
        "    eval_dataset=val_x,#tokenized_datasets[\"test\"],\n",
        "    #data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "TomAZeTc_FWm"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = Input(shape=(256,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': input_ids}\n",
        "\n",
        "# Load the Transformers BERT model as a layer in a Keras model\n",
        "bert_model = bert(inputs)[1]\n",
        "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
        "pooled_output = dropout(bert_model, training=False)\n",
        "\n",
        "# Then build your model output\n",
        "stance = Dense(units=len(data.stance_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='stance')(pooled_output)\n",
        "argument = Dense(units=len(data.argument_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='argument')(pooled_output)\n",
        "outputs = {'stance': stance, 'argument': argument}\n",
        "\n",
        "# And combine it all in a model object\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MXq9fPrHk_a",
        "outputId": "aac69a8b-c98c-4464-9f06-2c0d8440ccf6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"BERT_MultiLabel_MultiClass\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " bert (TFBertMainLayer)         TFBaseModelOutputWi  177853440   ['input_ids[0][0]']              \n",
            "                                thPoolingAndCrossAt                                               \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " pooled_output (Dropout)        (None, 768)          0           ['bert[1][1]']                   \n",
            "                                                                                                  \n",
            " argument (Dense)               (None, 4)            3076        ['pooled_output[0][0]']          \n",
            "                                                                                                  \n",
            " stance (Dense)                 (None, 4)            3076        ['pooled_output[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 177,859,592\n",
            "Trainable params: 177,859,592\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "svX4pHzUwAy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate=5e-05,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.95)\n",
        "\n",
        "optimizer = Adam(learning_rate=lr_schedule, epsilon=1e-08,\n",
        "    clipnorm=1.0, weight_decay=0.01)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'stance': CategoricalCrossentropy(from_logits = True), 'argument': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'stance': CategoricalAccuracy('accuracy'), 'argument': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    # x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    x={'input_ids': x['input_ids']},\n",
        "    y={'stance': y_stance, 'argument': y_argument},\n",
        "    validation_data=({'input_ids': val_x['input_ids'][:8]}, {'stance': val_y_stance[:8], 'argument': val_y_argument[:8]}),\n",
        "    batch_size=16,\n",
        "    epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_7_N3ODHzyX",
        "outputId": "972b65d7-1915-4709-f2ec-db8fc57c17c4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "315/315 [==============================] - 357s 957ms/step - loss: 0.8044 - argument_loss: 0.3610 - stance_loss: 0.4434 - argument_accuracy: 0.9067 - stance_accuracy: 0.8569 - val_loss: 3.7211 - val_argument_loss: 1.5235 - val_stance_loss: 2.1976 - val_argument_accuracy: 0.5000 - val_stance_accuracy: 0.2500\n",
            "Epoch 2/20\n",
            "315/315 [==============================] - 294s 934ms/step - loss: 1.7383 - argument_loss: 0.8229 - stance_loss: 0.9154 - argument_accuracy: 0.6714 - stance_accuracy: 0.6746 - val_loss: 2.2493 - val_argument_loss: 0.8320 - val_stance_loss: 1.4173 - val_argument_accuracy: 0.5000 - val_stance_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "315/315 [==============================] - 293s 931ms/step - loss: 1.6989 - argument_loss: 0.8041 - stance_loss: 0.8948 - argument_accuracy: 0.6837 - stance_accuracy: 0.6837 - val_loss: 2.3252 - val_argument_loss: 0.8096 - val_stance_loss: 1.5156 - val_argument_accuracy: 0.5000 - val_stance_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "315/315 [==============================] - 293s 931ms/step - loss: 1.4631 - argument_loss: 0.6880 - stance_loss: 0.7751 - argument_accuracy: 0.7407 - stance_accuracy: 0.7296 - val_loss: 1.0385 - val_argument_loss: 0.0686 - val_stance_loss: 0.9699 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 5/20\n",
            "315/315 [==============================] - 293s 929ms/step - loss: 0.6017 - argument_loss: 0.2551 - stance_loss: 0.3465 - argument_accuracy: 0.9333 - stance_accuracy: 0.8795 - val_loss: 0.9330 - val_argument_loss: 0.0555 - val_stance_loss: 0.8775 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 6/20\n",
            "315/315 [==============================] - 293s 929ms/step - loss: 0.5897 - argument_loss: 0.2495 - stance_loss: 0.3402 - argument_accuracy: 0.9347 - stance_accuracy: 0.8805 - val_loss: 0.7978 - val_argument_loss: 0.0786 - val_stance_loss: 0.7192 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "315/315 [==============================] - 293s 929ms/step - loss: 0.5762 - argument_loss: 0.2430 - stance_loss: 0.3332 - argument_accuracy: 0.9357 - stance_accuracy: 0.8815 - val_loss: 0.8840 - val_argument_loss: 0.1281 - val_stance_loss: 0.7559 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 8/20\n",
            "315/315 [==============================] - 293s 930ms/step - loss: 0.5730 - argument_loss: 0.2420 - stance_loss: 0.3310 - argument_accuracy: 0.9361 - stance_accuracy: 0.8819 - val_loss: 0.8059 - val_argument_loss: 0.0970 - val_stance_loss: 0.7088 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 9/20\n",
            "315/315 [==============================] - 292s 928ms/step - loss: 0.5759 - argument_loss: 0.2434 - stance_loss: 0.3326 - argument_accuracy: 0.9359 - stance_accuracy: 0.8817 - val_loss: 0.8782 - val_argument_loss: 0.1026 - val_stance_loss: 0.7755 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 10/20\n",
            "315/315 [==============================] - 292s 928ms/step - loss: 0.5745 - argument_loss: 0.2430 - stance_loss: 0.3315 - argument_accuracy: 0.9359 - stance_accuracy: 0.8817 - val_loss: 0.7326 - val_argument_loss: 0.0985 - val_stance_loss: 0.6341 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 11/20\n",
            "315/315 [==============================] - 293s 929ms/step - loss: 0.5730 - argument_loss: 0.2414 - stance_loss: 0.3316 - argument_accuracy: 0.9361 - stance_accuracy: 0.8817 - val_loss: 0.8281 - val_argument_loss: 0.0633 - val_stance_loss: 0.7648 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 12/20\n",
            "315/315 [==============================] - 292s 928ms/step - loss: 0.5728 - argument_loss: 0.2411 - stance_loss: 0.3316 - argument_accuracy: 0.9359 - stance_accuracy: 0.8817 - val_loss: 0.8385 - val_argument_loss: 0.0760 - val_stance_loss: 0.7625 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 13/20\n",
            "315/315 [==============================] - 293s 929ms/step - loss: 0.5861 - argument_loss: 0.2477 - stance_loss: 0.3384 - argument_accuracy: 0.9349 - stance_accuracy: 0.8807 - val_loss: 0.8520 - val_argument_loss: 0.1330 - val_stance_loss: 0.7190 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "315/315 [==============================] - 293s 929ms/step - loss: 0.5771 - argument_loss: 0.2431 - stance_loss: 0.3340 - argument_accuracy: 0.9359 - stance_accuracy: 0.8809 - val_loss: 0.8262 - val_argument_loss: 0.1186 - val_stance_loss: 0.7076 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 15/20\n",
            "315/315 [==============================] - 293s 930ms/step - loss: 0.5745 - argument_loss: 0.2423 - stance_loss: 0.3322 - argument_accuracy: 0.9357 - stance_accuracy: 0.8815 - val_loss: 0.8570 - val_argument_loss: 0.0806 - val_stance_loss: 0.7764 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 16/20\n",
            "315/315 [==============================] - 293s 929ms/step - loss: 0.5769 - argument_loss: 0.2434 - stance_loss: 0.3336 - argument_accuracy: 0.9357 - stance_accuracy: 0.8815 - val_loss: 0.8272 - val_argument_loss: 0.0842 - val_stance_loss: 0.7429 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 17/20\n",
            "315/315 [==============================] - 293s 929ms/step - loss: 0.5696 - argument_loss: 0.2401 - stance_loss: 0.3296 - argument_accuracy: 0.9361 - stance_accuracy: 0.8819 - val_loss: 0.9006 - val_argument_loss: 0.0661 - val_stance_loss: 0.8345 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "315/315 [==============================] - 292s 928ms/step - loss: 0.5736 - argument_loss: 0.2423 - stance_loss: 0.3313 - argument_accuracy: 0.9357 - stance_accuracy: 0.8815 - val_loss: 0.8288 - val_argument_loss: 0.0850 - val_stance_loss: 0.7438 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "315/315 [==============================] - 292s 928ms/step - loss: 0.5774 - argument_loss: 0.2440 - stance_loss: 0.3335 - argument_accuracy: 0.9357 - stance_accuracy: 0.8815 - val_loss: 0.8413 - val_argument_loss: 0.0966 - val_stance_loss: 0.7447 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "315/315 [==============================] - 292s 928ms/step - loss: 0.5847 - argument_loss: 0.2471 - stance_loss: 0.3376 - argument_accuracy: 0.9353 - stance_accuracy: 0.8811 - val_loss: 0.9148 - val_argument_loss: 0.0965 - val_stance_loss: 0.8183 - val_argument_accuracy: 1.0000 - val_stance_accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjTTd3mo2y8z",
        "outputId": "00e5423b-f4c3-4e86-d7d4-d4d6eac7486a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_results = model.predict(x={'input_ids': val_x['input_ids']})\n",
        "val[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
        "val[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)\n",
        "print(classification_report(val[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4XUe2Hz1ccY",
        "outputId": "a1d7b58e-e140-4ac4-8d95-88c72ba0ae72"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 33s 561ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      1173\n",
            "           1       0.00      0.00      0.00        42\n",
            "           2       0.62      0.97      0.76       312\n",
            "           3       0.00      0.00      0.00       153\n",
            "\n",
            "    accuracy                           0.88      1680\n",
            "   macro avg       0.40      0.49      0.44      1680\n",
            "weighted avg       0.80      0.88      0.83      1680\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(val[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGaNqYmy1d7Y",
        "outputId": "1456480e-60d5-4aa9-a72b-38263b3723df"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      1173\n",
            "           1       0.00      0.00      0.00        35\n",
            "           2       0.84      0.96      0.90       428\n",
            "           3       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.94      1680\n",
            "   macro avg       0.46      0.49      0.47      1680\n",
            "weighted avg       0.90      0.94      0.92      1680\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tdGuZBs61d-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_results = model.predict(x={'input_ids': val_x['input_ids']})"
      ],
      "metadata": {
        "id": "KH5X7vwPIO4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72d9d89-db83-42d6-a475-fab0e0e0aba9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 34s 567ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val[f'{CLASS_NAME}_stance_predict'] = val_results['stance'].argmax(axis=-1)\n",
        "val[f'{CLASS_NAME}_argument_predict'] = val_results['argument'].argmax(axis=-1)"
      ],
      "metadata": {
        "id": "am8mlOfhJuFd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(val[f'{CLASS_NAME}_stance'].values.tolist(), val_results['stance'].argmax(axis=-1), zero_division=0))"
      ],
      "metadata": {
        "id": "-zpWZCqNJuH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "686e634a-425b-41bf-eecb-ed8fc664934d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      1173\n",
            "           1       0.00      0.00      0.00        42\n",
            "           2       0.62      0.97      0.76       312\n",
            "           3       0.00      0.00      0.00       153\n",
            "\n",
            "    accuracy                           0.88      1680\n",
            "   macro avg       0.40      0.49      0.44      1680\n",
            "weighted avg       0.80      0.88      0.83      1680\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(val[f'{CLASS_NAME}_argument'].values.tolist(), val_results['argument'].argmax(axis=-1), zero_division=0))"
      ],
      "metadata": {
        "id": "joick4EpKGpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e40752-20e9-4fbf-b03c-02cdf249cf90"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      1173\n",
            "           1       0.00      0.00      0.00        35\n",
            "           2       0.84      0.96      0.90       428\n",
            "           3       0.00      0.00      0.00        44\n",
            "\n",
            "    accuracy                           0.94      1680\n",
            "   macro avg       0.46      0.49      0.47      1680\n",
            "weighted avg       0.90      0.94      0.92      1680\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testest_x = tokenizer(\n",
        "    text=test['text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding='max_length', \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "test_results = model.predict(x={'input_ids': testest_x['input_ids']})\n",
        "test[f'{CLASS_NAME}_stance_predict'] = test_results['stance'].argmax(axis=-1)\n",
        "test[f'{CLASS_NAME}_argument_predict'] = test_results['argument'].argmax(axis=-1)"
      ],
      "metadata": {
        "id": "onblnZpxWrin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[['text', f'{CLASS_NAME}_stance_predict', f'{CLASS_NAME}_argument_predict']].to_csv(f\"test_predict_{CLASS_NAME}.tsv\", sep='\\t', index=None)"
      ],
      "metadata": {
        "id": "pXVdQFTRKVpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NS5-KwtoVp3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(f\"val_predict_{CLASS_NAME}.tsv\", sep='\\t')\n",
        "df1.rename(columns={\"quarantine_stance_predict\": \"quarantine_stance\",\n",
        "                    \"quarantine_argument_predict\": \"quarantine_argument\"}, inplace=True)"
      ],
      "metadata": {
        "id": "uVYiGRnKVGK3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}