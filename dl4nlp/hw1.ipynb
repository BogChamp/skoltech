{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#Assignment - Transliteration","metadata":{"id":"KslYmMKMLY7V"}},{"cell_type":"markdown","source":"In this task you are required to solve the transliteration problem of names from English to Russian. Transliteration of a string means writing this string using the alphabet of another language with the preservation of pronunciation, although not always.\n","metadata":{"id":"NeC1UiR2LXiV"}},{"cell_type":"markdown","source":"## Instructions","metadata":{"id":"XvGHiezwIyt_"}},{"cell_type":"markdown","source":"To complete the assignment please do the following  steps (both are requred to get the full credits): \n\n###1. Complete this notebook\n\nUpload a filled notebook with code (this file). You will be asked to implement a transformer-based approach for transliteration.\n\nYou should implement your ``train`` and ``classify`` functions in this notebook in the cells below. Your model should be implemented as a special class/function in this notebook (be sure if you add any outer dependencies that everything is improted correctly and can be reproducable). \n\n\n###2. Submit solution to the shared task\n\nAfter the implementation of models' architectures you are asked to participate in the [competition](https://competitions.codalab.org/competitions/30932) to solve **Transliteration** task using your implemented code. \n\nYou should use your code from the previous part to train, validate, and generate predictions for the public (Practice) and private (Evaluation) test sets. It will produce predictions (`preds_translit.tsv`) for the dataset and score them if the true answers are present. You can use these scores to evaluate your model on dev set and choose the best one. Be sure to download the [dataset](https://github.com/skoltech-nlp/filimdb_evaluation/blob/master/TRANSLIT.tar.gz) and unzip it with `wget` command and run them from notebook cells. \n\nUpload obtained TSV file with your predictions (``preds_translit.tsv``) in ``.zip`` for the best results to both phases of the competition.\n\n\n**Important: You must indicate \"DL4NLP-23\" as your team name in Codalab. Without it your submission will be invalid!**\n","metadata":{"id":"Mop6m_5rIzu2"}},{"cell_type":"markdown","source":"## Basic algorithm","metadata":{"id":"GIr56czmR5FZ"}},{"cell_type":"markdown","source":"The basic algorithm is based on the following idea: for transliteration, alphabetic n-grams from one language can be transformed into another language into n-grams of the same size, using the most frequent transformation rule found according to statistics on the training sample. \n\nTo test the implementation, download the data, unzip the datasets, predict transliteration and run the evaluation script. To do this, you need to run the following commands:","metadata":{"id":"F9meQsrCR9xf"}},{"cell_type":"code","source":"!wget https://github.com/s-nlp/filimdb_evaluation/raw/master/TRANSLIT.tar.gz","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lf3-DST1YBx","outputId":"1aab9d10-a94d-4043-b7a2-a36ff992a5a6","execution":{"iopub.status.busy":"2023-04-12T12:17:41.552228Z","iopub.execute_input":"2023-04-12T12:17:41.552728Z","iopub.status.idle":"2023-04-12T12:17:43.330296Z","shell.execute_reply.started":"2023-04-12T12:17:41.552690Z","shell.execute_reply":"2023-04-12T12:17:43.329141Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2023-04-12 12:17:42--  https://github.com/s-nlp/filimdb_evaluation/raw/master/TRANSLIT.tar.gz\nResolving github.com (github.com)... 20.248.137.48\nConnecting to github.com (github.com)|20.248.137.48|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/s-nlp/filimdb_evaluation/master/TRANSLIT.tar.gz [following]\n--2023-04-12 12:17:42--  https://raw.githubusercontent.com/s-nlp/filimdb_evaluation/master/TRANSLIT.tar.gz\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1546458 (1.5M) [application/octet-stream]\nSaving to: ‘TRANSLIT.tar.gz’\n\nTRANSLIT.tar.gz     100%[===================>]   1.47M  --.-KB/s    in 0.01s   \n\n2023-04-12 12:17:43 (131 MB/s) - ‘TRANSLIT.tar.gz’ saved [1546458/1546458]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!gunzip TRANSLIT.tar.gz","metadata":{"id":"a1wUwZbT1lDd","execution":{"iopub.status.busy":"2023-04-12T12:17:46.668971Z","iopub.execute_input":"2023-04-12T12:17:46.669362Z","iopub.status.idle":"2023-04-12T12:17:47.648631Z","shell.execute_reply.started":"2023-04-12T12:17:46.669323Z","shell.execute_reply":"2023-04-12T12:17:47.647326Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!tar -xf TRANSLIT.tar","metadata":{"id":"pg5z4ezh1zO6","execution":{"iopub.status.busy":"2023-04-12T12:17:47.671919Z","iopub.execute_input":"2023-04-12T12:17:47.672509Z","iopub.status.idle":"2023-04-12T12:17:48.624080Z","shell.execute_reply.started":"2023-04-12T12:17:47.672452Z","shell.execute_reply":"2023-04-12T12:17:48.622556Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Baseline code","metadata":{"id":"umowx2OK4IJd"}},{"cell_type":"code","source":"from typing import List, Any\nfrom random import random\nimport collections as col\n\ndef baseline_train(\n        train_source_strings: List[str],\n        train_target_strings: List[str]) -> Any:\n    \"\"\"\n    Trains transliretation model on the given train set represented as\n    parallel list of input strings and their transliteration via labels.\n    :param train_source_strings: a list of strings, one str per example\n    :param train_target_strings: a list of strings, one str per example\n    :return: learnt parameters, or any object you like (it will be passed to the classify function)\n    \"\"\"\n\n    ngram_lvl = 3\n    def obtain_train_dicts(train_source_strings, train_target_strings,\n                            ngram_lvl):\n        ngrams_dict = col.defaultdict(lambda: col.defaultdict(int))\n        for src_str,dst_str in zip(train_source_strings,\n                                        train_target_strings):\n            try:\n                src_ngrams = [src_str[i:i+ngram_lvl] for i in\n                                range(len(src_str)-ngram_lvl+1)]\n                dst_ngrams = [dst_str[i:i+ngram_lvl] for i in\n                                range(len(dst_str)-ngram_lvl+1)]\n            except TypeError as e:\n                print(src_ngrams, dst_ngrams)\n                print(e)\n                raise StopIteration\n            for src_ngram in src_ngrams:\n                for dst_ngram in dst_ngrams:\n                    ngrams_dict[src_ngram][dst_ngram] += 1\n        return ngrams_dict\n        \n    ngrams_dict = col.defaultdict(lambda: col.defaultdict(int))\n    for nl in range(1, ngram_lvl+1):\n        ngrams_dict.update(\n            obtain_train_dicts(train_source_strings,\n                            train_target_strings, nl))\n    return ngrams_dict \n\n\ndef baseline_classify(strings: List[str], params: Any) -> List[str]:\n    \"\"\"\n    Classify strings given previously learnt parameters.\n    :param strings: strings to classify\n    :param params: parameters received from train function\n    :return: list of lists of predicted transliterated strings\n      (for each source string -> [top_1 prediction, .., top_k prediction]\n        if it is possible to generate more than one, otherwise\n        -> [prediction])\n        corresponding to the given list of strings\n    \"\"\"\n       \n    def predict_one_sample(sample, train_dict, ngram_lvl=1):\n        ngrams = [sample[i:i+ngram_lvl] for i in\n range(0,(len(sample) // ngram_lvl * ngram_lvl)-ngram_lvl+1, ngram_lvl)] +\\\n                 ([] if len(sample) % ngram_lvl == 0 else\n                    [sample[-(len(sample) % ngram_lvl):]])\n        prediction = ''\n        for ngram in ngrams:\n            ngram_dict = train_dict[ngram]\n            if len(ngram_dict.keys()) == 0:\n                prediction += '?'*len(ngram)\n            else:\n                prediction += max(ngram_dict, key=lambda k: ngram_dict[k])\n        return prediction \n    \n    ngram_lvl = 3\n    predictions = []\n    ngrams_dict = params\n    for string in strings:\n        top_1_pred = predict_one_sample(string, ngrams_dict,\n                                                ngram_lvl)\n        predictions.append([top_1_pred])\n    return predictions","metadata":{"id":"U0B2Vyk-4GvE","execution":{"iopub.status.busy":"2023-04-12T12:17:48.626990Z","iopub.execute_input":"2023-04-12T12:17:48.627918Z","iopub.status.idle":"2023-04-12T12:17:48.643502Z","shell.execute_reply.started":"2023-04-12T12:17:48.627873Z","shell.execute_reply":"2023-04-12T12:17:48.642433Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation code","metadata":{"id":"r7p9Nac-4X8C"}},{"cell_type":"code","source":"PREDS_FNAME = \"preds_translit_baseline.tsv\"\nSCORED_PARTS = ('train', 'dev', 'train_small', 'dev_small', 'test')\nTRANSLIT_PATH = \"TRANSLIT\"","metadata":{"id":"aOz9Miec58Tb","execution":{"iopub.status.busy":"2023-04-12T12:17:48.912711Z","iopub.execute_input":"2023-04-12T12:17:48.913370Z","iopub.status.idle":"2023-04-12T12:17:48.918250Z","shell.execute_reply.started":"2023-04-12T12:17:48.913334Z","shell.execute_reply":"2023-04-12T12:17:48.917179Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import codecs\nfrom pandas import read_csv\n\ndef load_dataset(data_dir_path=None, parts: List[str] = SCORED_PARTS):\n    part2ixy = {}\n    for part in parts:\n        path = os.path.join(data_dir_path, f'{part}.tsv')\n        with open(path, 'r', encoding='utf-8') as rf:\n            # first line is a header of the corresponding columns\n            lines = rf.readlines()[1:]\n            col_count = len(lines[0].strip('\\n').split('\\t'))\n            if col_count == 2:\n                strings, transliterations = zip(\n                    *list(map(lambda l: l.strip('\\n').split('\\t'), lines))\n                )\n            elif col_count == 1:\n                strings = list(map(lambda l: l.strip('\\n'), lines))\n                transliterations = None\n            else:\n                raise ValueError(\"wrong amount of columns\")\n        part2ixy[part] = (\n            [f'{part}/{i}' for i in range(len(strings))],\n            strings, transliterations,\n        )\n    return part2ixy\n\n\ndef load_transliterations_only(data_dir_path=None, parts: List[str] = SCORED_PARTS):\n    part2iy = {}\n    for part in parts:\n        path = os.path.join(data_dir_path, f'{part}.tsv')\n        with open(path, 'r', encoding='utf-8') as rf:\n            # first line is a header of the corresponding columns\n            lines = rf.readlines()[1:]\n            col_count = len(lines[0].strip('\\n').split('\\t'))\n            n_lines = len(lines)\n            if col_count == 2:\n                transliterations = [l.strip('\\n').split('\\t')[1] for l in lines]\n            elif col_count == 1:\n                transliterations = None\n            else:\n                raise ValueError(\"Wrong amount of columns\")\n        part2iy[part] = (\n            [f'{part}/{i}' for i in range(n_lines)],\n            transliterations,\n        )\n    return part2iy\n\n\ndef save_preds(preds, preds_fname):\n    \"\"\"\n    Save classifier predictions in format appropriate for scoring.\n    \"\"\"\n    with codecs.open(preds_fname, 'w') as outp:\n        for idx, preds in preds:\n            print(idx, *preds, sep='\\t', file=outp)\n    print('Predictions saved to %s' % preds_fname)\n\n\ndef load_preds(preds_fname, top_k=1):\n    \"\"\"\n    Load classifier predictions in format appropriate for scoring.\n    \"\"\"\n    kwargs = {\n        \"filepath_or_buffer\": preds_fname,\n        \"names\": [\"id\", \"pred\"],\n        \"sep\": '\\t',\n    }\n\n    pred_ids = list(read_csv(**kwargs, usecols=[\"id\"])[\"id\"])\n\n    pred_y = {\n        pred_id: [y]\n        for pred_id, y in zip(\n            pred_ids, read_csv(**kwargs, usecols=[\"pred\"])[\"pred\"]\n        )\n    }\n\n    for y in pred_y.values():\n        assert len(y) == top_k\n\n    return pred_ids, pred_y\n\n\ndef compute_hit_k(preds, k=10):\n    raise NotImplementedError\n\n\ndef compute_mrr(preds):\n    raise NotImplementedError\n\n\ndef compute_acc_1(preds, true):\n    right_answers = 0\n    bonus = 0\n    for pred, y in zip(preds, true):\n        if pred[0] == y:\n            right_answers += 1\n        elif pred[0] != pred[0] and y == 'нань':\n            print('Your test file contained empty string, skipping %f and %s' % (pred[0], y))\n            bonus += 1 # bugfix: skip empty line in test\n    return right_answers / (len(preds) - bonus)\n\n\ndef score(preds, true):\n    assert len(preds) == len(true), 'inconsistent amount of predictions and ground truth answers'\n    acc_1 = compute_acc_1(preds, true)\n    return {'acc@1': acc_1}\n\n\ndef score_preds(preds_path, data_dir, parts=SCORED_PARTS):\n    part2iy = load_transliterations_only(data_dir, parts=parts)\n    pred_ids, pred_dict = load_preds(preds_path)\n    # pred_dict = {i:y for i,y in zip(pred_ids, pred_y)}\n    scores = {}\n    for part, (true_ids, true_y) in part2iy.items():\n        if true_y is None:\n            print('no labels for %s set' % part)\n            continue\n        pred_y = [pred_dict[i] for i in true_ids]\n        score_values = score(pred_y, true_y)\n        acc_1 = score_values['acc@1']\n        print('%s set accuracy@1: %.2f' % (part, acc_1))\n        scores[part] = score_values \n    return scores","metadata":{"id":"SdbtMBxd52yX","execution":{"iopub.status.busy":"2023-04-12T12:17:54.411519Z","iopub.execute_input":"2023-04-12T12:17:54.411883Z","iopub.status.idle":"2023-04-12T12:17:54.433122Z","shell.execute_reply.started":"2023-04-12T12:17:54.411848Z","shell.execute_reply":"2023-04-12T12:17:54.431781Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Train and predict results","metadata":{"id":"Juwpml7Z8tbW"}},{"cell_type":"code","source":"from time import time\nimport numpy as np\nimport os\n\n\ndef train_and_predict(translit_path, scored_parts):\n    top_k = 1\n    part2ixy = load_dataset(translit_path, parts=scored_parts)\n    train_ids, train_strings, train_transliterations = part2ixy['train']\n    print('\\nTraining classifier on %d examples from train set ...' % len(train_strings))\n    st = time()\n    params = baseline_train(train_strings, train_transliterations)\n    print('Classifier trained in %.2fs' % (time() - st))\n\n    allpreds = []\n    for part, (ids, x, y) in part2ixy.items():\n        print('\\nClassifying %s set with %d examples ...' % (part, len(x)))\n        st = time()\n        preds = baseline_classify(x, params)\n        print('%s set classified in %.2fs' % (part, time() - st))\n        count_of_values = list(map(len, preds))\n        assert np.all(np.array(count_of_values) == top_k)\n        #score(preds, y)\n        allpreds.extend(zip(ids, preds))\n\n    save_preds(allpreds, preds_fname=PREDS_FNAME)\n    print('\\nChecking saved predictions ...')\n    return score_preds(preds_path=PREDS_FNAME, data_dir=translit_path, parts=scored_parts)","metadata":{"id":"VvOmwqtQ4URL","execution":{"iopub.status.busy":"2023-04-12T12:17:55.512262Z","iopub.execute_input":"2023-04-12T12:17:55.512939Z","iopub.status.idle":"2023-04-12T12:17:55.521782Z","shell.execute_reply.started":"2023-04-12T12:17:55.512899Z","shell.execute_reply":"2023-04-12T12:17:55.520530Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_and_predict(TRANSLIT_PATH, SCORED_PARTS)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KZ1GS3l28MRY","outputId":"261779f6-79a6-44a4-bcbd-b5cc248146b3","execution":{"iopub.status.busy":"2023-04-12T12:17:55.850855Z","iopub.execute_input":"2023-04-12T12:17:55.851190Z","iopub.status.idle":"2023-04-12T12:18:41.254689Z","shell.execute_reply.started":"2023-04-12T12:17:55.851160Z","shell.execute_reply":"2023-04-12T12:18:41.253692Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\nTraining classifier on 105371 examples from train set ...\nClassifier trained in 3.53s\n\nClassifying train set with 105371 examples ...\ntrain set classified in 24.54s\n\nClassifying dev set with 26342 examples ...\ndev set classified in 6.36s\n\nClassifying train_small set with 2000 examples ...\ntrain_small set classified in 0.46s\n\nClassifying dev_small set with 2000 examples ...\ndev_small set classified in 0.45s\n\nClassifying test set with 32926 examples ...\ntest set classified in 7.58s\nPredictions saved to preds_translit_baseline.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.33\ndev set accuracy@1: 0.31\ntrain_small set accuracy@1: 0.34\ndev_small set accuracy@1: 0.32\nno labels for test set\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'train': {'acc@1': 0.32907536229133255},\n 'dev': {'acc@1': 0.3112899552046162},\n 'train_small': {'acc@1': 0.3365},\n 'dev_small': {'acc@1': 0.323}}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Transformer-based approach","metadata":{"id":"VwXaPC4LiUMe"}},{"cell_type":"markdown","source":"\nTo implement your algorithm, use the template code, which needs to be modified.\n\nFirst, you need to add some details in the code of the Transformer architecture, implement the methods of the class `LrScheduler`, which is responsible for updating the learning rate during training.\nNext, you need to select the hyperparameters for the model according to the proposed guide.","metadata":{"id":"iM-9cKhbidfl"}},{"cell_type":"code","source":"!pip install Levenshtein","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nePd6qR5_sC-","outputId":"5ced3bf8-7862-427a-f7bb-774c6d021989","execution":{"iopub.status.busy":"2023-04-12T12:18:41.259503Z","iopub.execute_input":"2023-04-12T12:18:41.261768Z","iopub.status.idle":"2023-04-12T12:18:51.575259Z","shell.execute_reply.started":"2023-04-12T12:18:41.261729Z","shell.execute_reply":"2023-04-12T12:18:51.574075Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: Levenshtein in /opt/conda/lib/python3.7/site-packages (0.20.9)\nRequirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from Levenshtein) (2.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport pandas as pd\nimport numpy as np\nimport itertools as it\nimport collections as col\nimport random\nimport os\nimport copy\nimport json\nfrom tqdm.notebook import tqdm\nimport datetime, time\n\nimport copy\nimport os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as torch_data\nimport itertools as it\nimport collections as col\nimport random\n\nimport Levenshtein as le","metadata":{"id":"LQ5sfyjhBawp","execution":{"iopub.status.busy":"2023-04-12T12:18:51.577479Z","iopub.execute_input":"2023-04-12T12:18:51.577872Z","iopub.status.idle":"2023-04-12T12:18:53.681563Z","shell.execute_reply.started":"2023-04-12T12:18:51.577828Z","shell.execute_reply":"2023-04-12T12:18:53.680538Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Load dataset and embeddings","metadata":{"id":"r6enjcHrD_0Y"}},{"cell_type":"code","source":"def load_datasets(data_dir_path, parts):\n    datasets = {}\n    for part in parts:\n        path = os.path.join(data_dir_path, f'{part}.tsv')\n        datasets[part] = pd.read_csv(path, sep='\\t', na_filter=False)\n        print(f'Loaded {part} dataset, length: {len(datasets[part])}')\n    return datasets","metadata":{"id":"RmWG0dDUCFto","execution":{"iopub.status.busy":"2023-04-12T12:18:53.684096Z","iopub.execute_input":"2023-04-12T12:18:53.684731Z","iopub.status.idle":"2023-04-12T12:18:53.690508Z","shell.execute_reply.started":"2023-04-12T12:18:53.684691Z","shell.execute_reply":"2023-04-12T12:18:53.689354Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class TextEncoder:\n    def __init__(self, load_dir_path=None):\n        self.lang_keys = ['en', 'ru']\n        self.directions = ['id2token', 'token2id']\n        self.service_token_names = {\n            'pad_token': '<pad>',\n            'start_token': '<start>',\n            'unk_token': '<unk>',\n            'end_token': '<end>'\n        }\n        service_id2token = dict(enumerate(self.service_token_names.values()))\n        service_token2id ={v:k for k,v in service_id2token.items()}\n        self.service_vocabs = dict(zip(self.directions,\n                                       [service_id2token, service_token2id]))\n        if load_dir_path is None:\n            self.vocabs = {}\n            for lk in self.lang_keys:\n                self.vocabs[lk] = copy.deepcopy(self.service_vocabs)\n        else:\n            self.vocabs = self.load_vocabs(load_dir_path)\n    def load_vocabs(self, load_dir_path):\n        vocabs = {}\n        load_path = os.path.join(load_dir_path, 'vocabs')\n        for lk in self.lang_keys:\n            vocabs[lk] = {}\n            for d in self.directions:\n                columns = d.split('2')\n                print(lk, d)\n                df = pd.read_csv(os.path.join(load_path, f'{lk}_{d}'))\n                vocabs[lk][d] = dict(zip(*[df[c] for c in columns]))\n        return vocabs\n    \n    def save_vocabs(self, save_dir_path):\n        save_path = os.path.join(save_dir_path, 'vocabs')\n        os.makedirs(save_path, exist_ok=True)\n        for lk in self.lang_keys:\n            for d in self.directions:\n                columns = d.split('2')\n                pd.DataFrame(data=self.vocabs[lk][d].items(),\n                    columns=columns).to_csv(os.path.join(save_path, f'{lk}_{d}'),\n                                                index=False,\n                                                sep=',')\n    def make_vocabs(self, data_df):\n        for lk in self.lang_keys:\n            tokens = col.Counter(''.join(list(it.chain(*data_df[lk])))).keys()\n            part_id2t = dict(enumerate(tokens, start=len(self.service_token_names)))\n            part_t2id = {k:v for v,k in part_id2t.items()}\n            part_vocabs = [part_id2t, part_t2id]\n            for i in range(len(self.directions)):\n                self.vocabs[lk][self.directions[i]].update(part_vocabs[i])\n                \n        self.src_vocab_size = len(self.vocabs['en']['id2token'])\n        self.tgt_vocab_size = len(self.vocabs['ru']['id2token'])\n                \n    def frame(self, sample, start_token=None, end_token=None):\n        if start_token is None:\n            start_token=self.service_token_names['start_token']\n        if end_token is None:\n            end_token=self.service_token_names['end_token']\n        return [start_token] + sample + [end_token]\n    def token2id(self, samples, frame, lang_key):\n        if frame:\n            samples = list(map(self.frame, samples))\n        vocab = self.vocabs[lang_key]['token2id']\n        return list(map(lambda s:\n                        [vocab[t] if t in vocab.keys() else vocab[self.service_token_names['unk_token']]\n                         for t in s], samples))\n    \n    def unframe(self, sample, start_token=None, end_token=None):\n        if start_token is None:\n            start_token=self.service_vocabs['token2id'][self.service_token_names['start_token']]\n        if end_token is None:\n            end_token=self.service_vocabs['token2id'][self.service_token_names['end_token']]\n        pad_token=self.service_vocabs['token2id'][self.service_token_names['pad_token']]\n        return list(it.takewhile(lambda e: e != end_token and e != pad_token, sample[1:]))\n    def id2token(self, samples, unframe, lang_key):\n        if unframe:\n            samples = list(map(self.unframe, samples))\n        vocab = self.vocabs[lang_key]['id2token']\n        return list(map(lambda s:\n                        [vocab[idx] if idx in vocab.keys() else self.service_token_names['unk_token'] for idx in s], samples))\n\n\nclass TranslitData(torch_data.Dataset):\n    def __init__(self, source_strings, target_strings,\n                text_encoder):\n        super(TranslitData, self).__init__()\n        self.source_strings = source_strings\n        self.text_encoder = text_encoder\n        if target_strings is not None:\n            assert len(source_strings) == len(target_strings)\n            self.target_strings = target_strings\n        else:\n            self.target_strings = None\n    def __len__(self):\n        return len(self.source_strings)\n    def __getitem__(self, idx):\n        src_str = self.source_strings[idx]\n        encoder_input = self.text_encoder.token2id([list(src_str)], frame=True, lang_key='en')[0]\n        if self.target_strings is not None:\n            tgt_str = self.target_strings[idx]\n            tmp = self.text_encoder.token2id([list(tgt_str)], frame=True, lang_key='ru')[0]\n            decoder_input = tmp[:-1]\n            decoder_target = tmp[1:]\n            return (encoder_input, decoder_input, decoder_target)\n        else:\n            return (encoder_input,)\n\n\nclass BatchSampler(torch_data.BatchSampler):\n    def __init__(self, sampler, batch_size, drop_last, shuffle_each_epoch):\n        super(BatchSampler, self).__init__(sampler, batch_size, drop_last)\n        self.batches = []\n        for b in super(BatchSampler, self).__iter__():\n            self.batches.append(b)\n        self.shuffle_each_epoch = shuffle_each_epoch\n        if self.shuffle_each_epoch:\n            random.shuffle(self.batches)\n        self.index = 0\n        #print(f'Batches collected: {len(self.batches)}')\n    def __iter__(self):\n        self.index = 0\n        return self\n    def __next__(self):\n        if self.index == len(self.batches):\n            if self.shuffle_each_epoch:\n                random.shuffle(self.batches)\n            raise StopIteration\n        else:\n            batch = self.batches[self.index]\n            self.index += 1\n            return batch\n\ndef collate_fn(batch_list):\n    '''batch_list can store either 3 components:\n        encoder_inputs, decoder_inputs, decoder_targets\n        or single component: encoder_inputs'''\n    components = list(zip(*batch_list))\n    batch_tensors = []\n    for data in components:\n        max_len = max([len(sample) for sample in data])\n        #print(f'Maximum length in batch = {max_len}')\n        sample_tensors = [torch.tensor(s, requires_grad=False, dtype=torch.int64)\n                         for s in data]\n        batch_tensors.append(nn.utils.rnn.pad_sequence(\n            sample_tensors,\n            batch_first=True, padding_value=0))\n    return tuple(batch_tensors) \n\n\ndef create_dataloader(source_strings, target_strings,\n                      text_encoder, batch_size,\n                      shuffle_batches_each_epoch):\n    '''target_strings parameter can be None'''\n    dataset = TranslitData(source_strings, target_strings,\n                                text_encoder=text_encoder)\n    seq_sampler = torch_data.SequentialSampler(dataset)\n    batch_sampler = BatchSampler(seq_sampler, batch_size=batch_size,\n                                drop_last=False,\n                                shuffle_each_epoch=shuffle_batches_each_epoch)\n    dataloader = torch_data.DataLoader(dataset,\n                                       batch_sampler=batch_sampler,\n                                       collate_fn=collate_fn)\n    return dataloader","metadata":{"id":"-gMDFNVt-nMw","execution":{"iopub.status.busy":"2023-04-12T12:18:53.692038Z","iopub.execute_input":"2023-04-12T12:18:53.692663Z","iopub.status.idle":"2023-04-12T12:18:53.726544Z","shell.execute_reply.started":"2023-04-12T12:18:53.692624Z","shell.execute_reply":"2023-04-12T12:18:53.725369Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Metric function","metadata":{"id":"-Qsehb_eERRF"}},{"cell_type":"code","source":"def compute_metrics(predicted_strings, target_strings, metrics):\n    metric_values = {}\n    for m in metrics:\n        if m == 'acc@1':\n            metric_values[m] = sum(predicted_strings == target_strings) / len(target_strings)\n        elif m =='mean_ld@1':\n            metric_values[m] =\\\n                np.mean(list(map(lambda e: le.distance(*e), zip(predicted_strings, target_strings))))\n        else: \n            raise ValueError(f'Unknown metric: {m}')\n    return metric_values","metadata":{"id":"MN4I60GqETB0","execution":{"iopub.status.busy":"2023-04-12T12:18:53.727818Z","iopub.execute_input":"2023-04-12T12:18:53.728176Z","iopub.status.idle":"2023-04-12T12:18:53.740403Z","shell.execute_reply.started":"2023-04-12T12:18:53.728139Z","shell.execute_reply":"2023-04-12T12:18:53.739488Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"###  Positional Encoding","metadata":{"id":"UiYl5XsdkmZG"}},{"cell_type":"markdown","source":"As you remember, Transformer treats an input sequence of elements as a time series. Since the Encoder inside the Transformer simultaneously processes the entire input sequence, the information about the position of the element needs to be encoded inside its embedding, since it is not identified in any other way inside the model. That is why the PositionalEncoding layer is used, which sums embeddings with a vector of the same dimension.\nLet the matrix of these vectors for each position of the time series be denoted as $PE$. Then the elements of the matrix are:\n\n$$ PE_{(pos,2i)} = \\sin{(pos/10000^{2i/d_{model}})}$$\n$$ PE_{(pos,2i+1)} = \\cos{(pos/10000^{2i/d_{model}})}$$\n\nwhere $pos$ - is the position, $i$ - index of the component of the corresponging vector, $d_{model}$ - dimension of each vector. Thus, even components represent sine values, and odd ones represent cosine values with different arguments.\n\nIn this task you are required to implement these formulas inside the class constructor *PositionalEncoding* in the main file ``translit.py``, which you are to upload. To run the test use the following function:\n\n`test_positional_encoding()`\n\nMake sure that there is no any `AssertionError`!\n","metadata":{"id":"vkNaSzwrkpf_"}},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, hidden_size, vocab_size):\n        super(Embedding, self).__init__()\n        self.emb_layer = nn.Embedding(vocab_size, hidden_size)\n        self.hidden_size = hidden_size\n\n    def forward(self, x):\n        return self.emb_layer(x)\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, hidden_size, max_len=512):\n        super(PositionalEncoding, self).__init__()\n        pe = torch.zeros(max_len, hidden_size, requires_grad=False)\n        position = torch.arange(0, max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, hidden_size, 2) * -(np.log(10000.0) / hidden_size))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        # pe shape: (1, max_len, hidden_size)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        # x: shape (batch size, sequence length, hidden size)\n        x = x + self.pe[:, :x.size(1)]\n        return x","metadata":{"id":"Rm4g1vybAKZs","execution":{"iopub.status.busy":"2023-04-12T12:18:53.741785Z","iopub.execute_input":"2023-04-12T12:18:53.742230Z","iopub.status.idle":"2023-04-12T12:18:53.752746Z","shell.execute_reply.started":"2023-04-12T12:18:53.742192Z","shell.execute_reply":"2023-04-12T12:18:53.751579Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def test_positional_encoding():\n    pe = PositionalEncoding(max_len=3, hidden_size=4)\n    res_1 = torch.tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000],\n                           [ 0.8415,  0.5403,  0.0100,  0.9999],\n                           [ 0.9093, -0.4161,  0.0200,  0.9998]]])\n    # print(pe.pe - res_1)\n    assert torch.all(torch.abs(pe.pe - res_1) < 1e-4).item()\n    print('Test is passed!')","metadata":{"id":"hBk6uxQyCqt-","execution":{"iopub.status.busy":"2023-04-12T12:18:53.754419Z","iopub.execute_input":"2023-04-12T12:18:53.754809Z","iopub.status.idle":"2023-04-12T12:18:53.764049Z","shell.execute_reply.started":"2023-04-12T12:18:53.754772Z","shell.execute_reply":"2023-04-12T12:18:53.763025Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_positional_encoding()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vwN9Qk_NCw-K","outputId":"9f06bc6b-6d5c-4dc7-be1a-1afb0e0a8f57","execution":{"iopub.status.busy":"2023-04-12T12:18:53.765568Z","iopub.execute_input":"2023-04-12T12:18:53.765936Z","iopub.status.idle":"2023-04-12T12:18:53.870190Z","shell.execute_reply.started":"2023-04-12T12:18:53.765901Z","shell.execute_reply":"2023-04-12T12:18:53.869283Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Test is passed!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### LayerNorm","metadata":{"id":"g026bdkrEtiQ"}},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    \"Layer Normalization layer\"\n\n    def __init__(self, hidden_size, eps=1e-6):\n        super(LayerNorm, self).__init__()\n        self.gain = nn.Parameter(torch.ones(hidden_size))\n        self.bias = nn.Parameter(torch.zeros(hidden_size))\n        self.eps = eps\n\n    def forward(self, x):\n        mean = x.mean(-1, keepdim=True)\n        std = x.std(-1, keepdim=True)\n        return self.gain * (x - mean) / (std + self.eps) + self.bias","metadata":{"id":"dIMy52O9Es0K","execution":{"iopub.status.busy":"2023-04-12T12:18:53.874256Z","iopub.execute_input":"2023-04-12T12:18:53.874547Z","iopub.status.idle":"2023-04-12T12:18:53.881566Z","shell.execute_reply.started":"2023-04-12T12:18:53.874521Z","shell.execute_reply":"2023-04-12T12:18:53.880308Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### SublayerConnection","metadata":{"id":"TEpsKqLwE3hB"}},{"cell_type":"code","source":"class SublayerConnection(nn.Module):\n    \"\"\"\n    A residual connection followed by a layer normalization.\n    \"\"\"\n\n    def __init__(self, hidden_size, dropout):\n        super(SublayerConnection, self).__init__()\n        self.layer_norm = LayerNorm(hidden_size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, sublayer):\n        return self.layer_norm(x + self.dropout(sublayer(x)))\n\ndef padding_mask(x, pad_idx=0):\n    assert len(x.size()) >= 2\n    return (x != pad_idx).unsqueeze(-2)\n\ndef look_ahead_mask(size):\n    \"Mask out the right context\"\n    attn_shape = (1, size, size)\n    look_ahead_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n    return torch.from_numpy(look_ahead_mask) == 0\n\ndef compositional_mask(x, pad_idx=0):\n    pm = padding_mask(x, pad_idx=pad_idx)\n    seq_length = x.size(-1)\n    result_mask = pm & \\\n                  look_ahead_mask(seq_length).type_as(pm.data)\n    return result_mask","metadata":{"id":"2yuMxRinE3uH","execution":{"iopub.status.busy":"2023-04-12T12:18:53.882855Z","iopub.execute_input":"2023-04-12T12:18:53.883897Z","iopub.status.idle":"2023-04-12T12:18:53.894647Z","shell.execute_reply.started":"2023-04-12T12:18:53.883856Z","shell.execute_reply":"2023-04-12T12:18:53.893445Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### FeedForward","metadata":{"id":"Kh86csH_FCyB"}},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self, hidden_size, ff_hidden_size, dropout=0.1):\n        super(FeedForward, self).__init__()\n        self.pre_linear = nn.Linear(hidden_size, ff_hidden_size)\n        self.post_linear = nn.Linear(ff_hidden_size, hidden_size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        return self.post_linear(self.dropout(F.relu(self.pre_linear(x))))\n\ndef clone_layer(module, N):\n    \"Produce N identical layers.\"\n    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])","metadata":{"id":"4zy1PNwlGIEX","execution":{"iopub.status.busy":"2023-04-12T12:18:53.896037Z","iopub.execute_input":"2023-04-12T12:18:53.896515Z","iopub.status.idle":"2023-04-12T12:18:53.906199Z","shell.execute_reply.started":"2023-04-12T12:18:53.896478Z","shell.execute_reply":"2023-04-12T12:18:53.905222Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"###  MultiHeadAttention","metadata":{"id":"IwoQ_X8ylJYN"}},{"cell_type":"markdown","source":"\nThen you are required to implement `attention` method in the class  `MultiHeadAttention`. The MultiHeadAttention layer takes as input  query vectors, key and value vectors for each step of the sequence of matrices  Q,K,V correspondingly. Each key vector, value vector, and query vector is obtained as a result of linear projection using one of three trained vector parameter matrices from the previous layer. This semantics can be represented in the form of formulas:\n$$\nAttention(Q, K, V)=softmax\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}\\right) V\\\\\n$$\n\n$$\nMultiHead(Q, K, V) = Concat\\left(head_1, ... , head_h\\right) W^O\\\\\n$$\n\n$$\nhead_i=Attention\\left(Q W_i^Q, K W_i^K, V W_i^V\\right)\\\\\n$$\n$h$ - the number of attention heads - parallel sub-layers for Scaled Dot-Product Attention on a vector of smaller dimension ($d_{k} = d_{q} = d_{v} = d_{model} / h$). \nThe logic of  \\texttt{MultiHeadAttention} is presented in the picture (from original  [paper](https://arxiv.org/abs/1706.03762)):\n\n![](https://lilianweng.github.io/lil-log/assets/images/transformer.png)\n\n\nInside a method `attention` you are required to create a dropout layer from  MultiHeadAttention class constructor. Dropout layer is to be applied directly on the attention weights - the result of softmax operation. Value of drop probability  can be regulated in the train in the `model_config['dropout']['attention']`.\n\nThe correctness of implementation can be checked with\n`test_multi_head_attention()`\n\n","metadata":{"id":"SYGVEp3mkgNf"}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, n_heads, hidden_size, dropout=None):\n        super(MultiHeadAttention, self).__init__()\n        assert hidden_size % n_heads == 0\n        self.head_hidden_size = hidden_size // n_heads\n        self.n_heads = n_heads\n        self.linears = clone_layer(nn.Linear(hidden_size, hidden_size), 4)\n        self.attn_weights = None\n        self.dropout = dropout\n        if self.dropout is not None:\n            self.dropout_layer = nn.Dropout(p=self.dropout)\n\n    def attention(self, query, key, value, mask):\n        \"\"\"Compute 'Scaled Dot Product Attention'\n            query, key and value tensors have the same shape:\n                (batch size, number of heads, sequence length, head hidden size)\n            mask shape: (batch size, 1, sequence length, sequence length)\n                '1' dimension value will be broadcasted to number of heads inside your operations\n            mask should be applied before using softmax to get attn_weights\n        \"\"\"\n        ## attn_weights shape: (batch size, number of heads, sequence length, sequence length)\n        ## output shape: (batch size, number of heads, sequence length, head hidden size)\n        ## TODO: provide your implementation here\n        ## don't forget to apply dropout to attn_weights if self.dropout is not None\n        d_k = query.size(-1)\n        scores = torch.matmul(query, key.transpose(-2, -1)) / np.sqrt(d_k)\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n        attn_weights = F.softmax(scores, dim = -1)\n        if self.dropout is not None:\n            attn_weights = self.dropout_layer(attn_weights)\n\n        output = torch.matmul(attn_weights, value)\n        return output, attn_weights\n\n    def forward(self, query, key, value, mask=None):\n        if mask is not None:\n            # Same mask applied to all h heads.\n            mask = mask.unsqueeze(1)\n        batch_size = query.size(0)\n\n        # Split vectors for different attention heads (from hidden_size => n_heads x head_hidden_size)\n        # and do separate linear projection, for separate trainable weights\n        query, key, value = \\\n            [l(x).view(batch_size, -1, self.n_heads, self.head_hidden_size).transpose(1, 2)\n             for l, x in zip(self.linears, (query, key, value))]\n\n        x, self.attn_weights = self.attention(query, key, value, mask=mask)\n        # x shape: (batch size, number of heads, sequence length, head hidden size)\n        # self.attn_weights shape: (batch size, number of heads, sequence length, sequence length)\n\n        # Concatenate the output of each head\n        x = x.transpose(1, 2).contiguous() \\\n            .view(batch_size, -1, self.n_heads * self.head_hidden_size)\n\n        return self.linears[-1](x)","metadata":{"id":"5q7mpdjnAVHP","execution":{"iopub.status.busy":"2023-04-12T12:18:53.907818Z","iopub.execute_input":"2023-04-12T12:18:53.908338Z","iopub.status.idle":"2023-04-12T12:18:53.921185Z","shell.execute_reply.started":"2023-04-12T12:18:53.908301Z","shell.execute_reply":"2023-04-12T12:18:53.920032Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def test_multi_head_attention():\n    mha = MultiHeadAttention(n_heads=1, hidden_size=5, dropout=None)\n    # batch_size == 2, sequence length == 3, hidden_size == 5\n    # query = torch.arange(150).reshape(2, 3, 5)\n    query = torch.tensor([[[[ 0.64144618, -0.95817388,  0.37432297,  0.58427106,\n          -0.94668716]],\n        [[-0.23199289,  0.66329209, -0.46507035, -0.54272512,\n          -0.98640698]],\n        [[ 0.07546638, -0.09277002,  0.20107185, -0.97407381,\n          -0.27713414]]],\n       [[[ 0.14727783,  0.4747886 ,  0.44992016, -0.2841419 ,\n          -0.81820319]],\n        [[-0.72324994,  0.80643179, -0.47655449,  0.45627872,\n           0.60942404]],\n        [[ 0.61712569, -0.62947282, -0.95215713, -0.38721959,\n          -0.73289725]]]])\n    key = torch.tensor([[[[-0.81759856, -0.60049991, -0.05923424,  0.51898901,\n          -0.3366209 ]],\n        [[ 0.83957818, -0.96361722,  0.62285191,  0.93452467,\n           0.51219613]],\n        [[-0.72758847,  0.41256154,  0.00490795,  0.59892503,\n          -0.07202049]]],\n       [[[ 0.72315339, -0.49896314,  0.94254637, -0.54356006,\n          -0.04837949]],\n        [[ 0.51759322, -0.43927061, -0.59924184,  0.92241702,\n          -0.86811696]],\n        [[-0.54322046, -0.92323003, -0.827746  ,  0.90842783,\n           0.88428119]]]])\n    value = torch.tensor([[[[-0.83895431,  0.805027  ,  0.22298283, -0.84849915,\n          -0.34906026]],\n        [[-0.02899652, -0.17456128, -0.17535998, -0.73160314,\n          -0.13468061]],\n        [[ 0.75234265,  0.02675947,  0.84766286, -0.5475651 ,\n          -0.83319316]]],\n       [[[-0.47834413,  0.34464645, -0.41921457,  0.33867964,\n           0.43470836]],\n        [[-0.99000979,  0.10220893, -0.4932273 ,  0.95938905,\n           0.01927012]],\n        [[ 0.91607137,  0.57395644, -0.90914179,  0.97212912,\n           0.33078759]]]])\n    query = query.float().transpose(1,2)\n    key = key.float().transpose(1,2)\n    value = value.float().transpose(1,2)\n\n    x,_ = torch.max(query[:,0,:,:], axis=-1)\n    mask = compositional_mask(x)\n    mask.unsqueeze_(1)\n    for n,t in [('query', query), ('key', key), ('value', value), ('mask', mask)]:\n        print(f'Name: {n}, shape: {t.size()}')\n    with torch.no_grad():\n        output, attn_weights = mha.attention(query, key, value, mask=mask)\n    assert output.size() == torch.Size([2,1,3,5])\n    assert attn_weights.size() == torch.Size([2,1,3,3])\n\n    truth_output = torch.tensor([[[[-0.8390,  0.8050,  0.2230, -0.8485, -0.3491],\n          [-0.6043,  0.5212,  0.1076, -0.8146, -0.2870],\n          [-0.0665,  0.2461,  0.3038, -0.7137, -0.4410]]],\n        [[[-0.4783,  0.3446, -0.4192,  0.3387,  0.4347],\n          [-0.7959,  0.1942, -0.4652,  0.7239,  0.1769],\n          [-0.3678,  0.2868, -0.5799,  0.7987,  0.2086]]]])\n    truth_attn_weights = torch.tensor([[[[1.0000, 0.0000, 0.0000],\n          [0.7103, 0.2897, 0.0000],\n          [0.3621, 0.3105, 0.3274]]],\n        [[[1.0000, 0.0000, 0.0000],\n          [0.3793, 0.6207, 0.0000],\n          [0.2642, 0.4803, 0.2555]]]])\n    # print(torch.abs(output - truth_output))\n    # print(torch.abs(attn_weights - truth_attn_weights))\n    assert torch.all(torch.abs(output - truth_output) < 1e-4).item()\n    assert torch.all(torch.abs(attn_weights - truth_attn_weights) < 1e-4).item()\n    print('Test is passed!')","metadata":{"id":"ExHkza22FCF0","execution":{"iopub.status.busy":"2023-04-12T12:18:53.922839Z","iopub.execute_input":"2023-04-12T12:18:53.923261Z","iopub.status.idle":"2023-04-12T12:18:53.943518Z","shell.execute_reply.started":"2023-04-12T12:18:53.923225Z","shell.execute_reply":"2023-04-12T12:18:53.942482Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"test_multi_head_attention()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GI6yMbX8FhGZ","outputId":"f0c76311-bed9-4e6d-bd9f-746326d4195f","execution":{"iopub.status.busy":"2023-04-12T12:18:53.946864Z","iopub.execute_input":"2023-04-12T12:18:53.947997Z","iopub.status.idle":"2023-04-12T12:18:53.982758Z","shell.execute_reply.started":"2023-04-12T12:18:53.947961Z","shell.execute_reply":"2023-04-12T12:18:53.981719Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Name: query, shape: torch.Size([2, 1, 3, 5])\nName: key, shape: torch.Size([2, 1, 3, 5])\nName: value, shape: torch.Size([2, 1, 3, 5])\nName: mask, shape: torch.Size([2, 1, 3, 3])\nTest is passed!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Encoder","metadata":{"id":"LUdLLSojGJbM"}},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    \"Encoder is made up of self-attn and feed forward (defined below)\"\n\n    def __init__(self, hidden_size, ff_hidden_size, n_heads, dropout):\n        super(EncoderLayer, self).__init__()\n        self.self_attn = MultiHeadAttention(n_heads, hidden_size,\n                                            dropout=dropout['attention'])\n        self.feed_forward = FeedForward(hidden_size, ff_hidden_size,\n                                        dropout=dropout['relu'])\n        self.sublayers = clone_layer(SublayerConnection(hidden_size, dropout['residual']), 2)\n\n    def forward(self, x, mask):\n        x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, mask))\n        return self.sublayers[1](x, self.feed_forward)\n\nclass Encoder(nn.Module):\n    def __init__(self, config):\n        super(Encoder, self).__init__()\n        self.embedder = Embedding(config['hidden_size'],\n                                  config['src_vocab_size'])\n        self.positional_encoder = PositionalEncoding(config['hidden_size'],\n                                                     max_len=config['max_src_seq_length'])\n        self.embedding_dropout = nn.Dropout(p=config['dropout']['embedding'])\n        self.encoder_layer = EncoderLayer(config['hidden_size'],\n                                          config['ff_hidden_size'],\n                                          config['n_heads'],\n                                          config['dropout'])\n        self.layers = clone_layer(self.encoder_layer, config['n_layers'])\n        self.layer_norm = LayerNorm(config['hidden_size'])\n\n    def forward(self, x, mask):\n        \"Pass the input (and mask) through each layer in turn.\"\n        x = self.embedding_dropout(self.positional_encoder(self.embedder(x)))\n        for layer in self.layers:\n            x = layer(x, mask)\n        return self.layer_norm(x)","metadata":{"id":"dFMMTX4NA0KP","execution":{"iopub.status.busy":"2023-04-12T12:18:53.984329Z","iopub.execute_input":"2023-04-12T12:18:53.984686Z","iopub.status.idle":"2023-04-12T12:18:53.994996Z","shell.execute_reply.started":"2023-04-12T12:18:53.984651Z","shell.execute_reply":"2023-04-12T12:18:53.993845Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Decoder","metadata":{"id":"6kyeSkMeGQo_"}},{"cell_type":"code","source":"class DecoderLayer(nn.Module):\n    \"\"\"\n    Decoder is made of 3 sublayers: self attention, encoder-decoder attention\n    and feed forward\"\n    \"\"\"\n\n    def __init__(self, hidden_size, ff_hidden_size, n_heads, dropout):\n        super(DecoderLayer, self).__init__()\n\n        self.self_attn = MultiHeadAttention(n_heads, hidden_size,\n                                            dropout=dropout['attention'])\n        self.encdec_attn = MultiHeadAttention(n_heads, hidden_size,\n                                              dropout=dropout['attention'])\n        self.feed_forward = FeedForward(hidden_size, ff_hidden_size,\n                                        dropout=dropout['relu'])\n        self.sublayers = clone_layer(SublayerConnection(hidden_size, dropout['residual']), 3)\n\n    def forward(self, x, encoder_output, encoder_mask, decoder_mask):\n        x = self.sublayers[0](x, lambda x: self.self_attn(x, x, x, decoder_mask))\n        x = self.sublayers[1](x, lambda x: self.encdec_attn(x, encoder_output,\n                                                            encoder_output, encoder_mask))\n        return self.sublayers[2](x, self.feed_forward)\n\nclass Decoder(nn.Module):\n    def __init__(self, config):\n        super(Decoder, self).__init__()\n        self.embedder = Embedding(config['hidden_size'],\n                                  config['tgt_vocab_size'])\n        self.positional_encoder = PositionalEncoding(config['hidden_size'],\n                                                     max_len=config['max_tgt_seq_length'])\n        self.embedding_dropout = nn.Dropout(p=config['dropout']['embedding'])\n        self.decoder_layer = DecoderLayer(config['hidden_size'],\n                                          config['ff_hidden_size'],\n                                          config['n_heads'],\n                                          config['dropout'])\n        self.layers = clone_layer(self.decoder_layer, config['n_layers'])\n        self.layer_norm = LayerNorm(config['hidden_size'])\n\n    def forward(self, x, encoder_output, encoder_mask, decoder_mask):\n        x = self.embedding_dropout(self.positional_encoder(self.embedder(x)))\n        for layer in self.layers:\n            x = layer(x, encoder_output, encoder_mask, decoder_mask)\n        return self.layer_norm(x)","metadata":{"id":"B4pSnS8NGPyf","execution":{"iopub.status.busy":"2023-04-12T12:18:53.996707Z","iopub.execute_input":"2023-04-12T12:18:53.997485Z","iopub.status.idle":"2023-04-12T12:18:54.010330Z","shell.execute_reply.started":"2023-04-12T12:18:53.997428Z","shell.execute_reply":"2023-04-12T12:18:54.009254Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Transformer","metadata":{"id":"bwP_NVeYGY-j"}},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, config):\n        super(Transformer, self).__init__()\n        self.config = config\n        self.encoder = Encoder(config)\n        self.decoder = Decoder(config)\n        self.proj = nn.Linear(config['hidden_size'], config['tgt_vocab_size'])\n\n        self.pad_idx = config['pad_idx']\n        self.tgt_vocab_size = config['tgt_vocab_size']\n\n    def encode(self, encoder_input, encoder_input_mask):\n        return self.encoder(encoder_input, encoder_input_mask)\n\n    def decode(self, encoder_output, encoder_input_mask, decoder_input, decoder_input_mask):\n        return self.decoder(decoder_input, encoder_output, encoder_input_mask, decoder_input_mask)\n\n    def linear_project(self, x):\n        return self.proj(x)\n\n    def forward(self, encoder_input, decoder_input):\n        encoder_input_mask = padding_mask(encoder_input, pad_idx=self.config['pad_idx'])\n        decoder_input_mask = compositional_mask(decoder_input, pad_idx=self.config['pad_idx'])\n        encoder_output = self.encode(encoder_input, encoder_input_mask)\n        decoder_output = self.decode(encoder_output, encoder_input_mask,\n                                     decoder_input, decoder_input_mask)\n        output_logits = self.linear_project(decoder_output)\n        return output_logits\n\n\ndef prepare_model(config):\n    model = Transformer(config)\n\n    for p in model.parameters():\n        if p.dim() > 1:\n            nn.init.xavier_uniform_(p)\n    return model","metadata":{"id":"mVTRK_5cGYYa","execution":{"iopub.status.busy":"2023-04-12T12:18:54.013704Z","iopub.execute_input":"2023-04-12T12:18:54.014313Z","iopub.status.idle":"2023-04-12T12:18:54.025313Z","shell.execute_reply.started":"2023-04-12T12:18:54.014286Z","shell.execute_reply":"2023-04-12T12:18:54.024352Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"####  LrScheduler","metadata":{"id":"wnmPBcVyrR6h"}},{"cell_type":"markdown","source":"The last thing you have to prepare is the class  `LrScheduler`, which is in charge of  learning rate updating after every step of the optimizer. You are required to fill the class constructor and the method `learning_rate`. The preferable stratagy of updating the learning rate (lr), is the following two stages:\n\n* \"warmup\" stage - lr linearly increases until the defined value during the fixed number of steps (the proportion of all training steps - the parameter `train_config['warmup\\_steps\\_part']` in the train function). \n* \"decrease\" stage - lr linearly decreases until 0 during the left training steps.\n\n`learning_rate()` call should return the value of  lr at this step,  which number is stored at self.step. The class constructor takes not only `warmup_steps_part` but the peak learning rate value `lr_peak` at the end of \"warmup\" stage and a string name of the strategy of learning rate scheduling. You can test other strategies if you want to with `self.type attribute`. \n\nCorrectness check: `test_lr_scheduler()`\n","metadata":{"id":"2luuBDZFrTj1"}},{"cell_type":"code","source":"class LrScheduler:\n    def __init__(self, n_steps, **kwargs):\n        self.type = kwargs['type']\n        if self.type == 'warmup,decay_linear':\n            ## TODO: provide your implementation here\n            self.n_steps = n_steps\n            self.warmup_steps_part = kwargs['warmup_steps_part']\n            self.lr_peak = kwargs['lr_peak']\n        else:\n            raise ValueError(f'Unknown type argument: {self.type}')\n        self._step = 0\n        self._lr = 0\n\n    def step(self, optimizer):\n        self._step += 1\n        lr = self.learning_rate()\n        for p in optimizer.param_groups:\n            p['lr'] = lr\n\n    def learning_rate(self, step=None):\n        if step is None:\n            step = self._step\n        if self.type == 'warmup,decay_linear':\n            ## TODO: provide your implementation here\n            if step < self.n_steps * self.warmup_steps_part:\n                self._lr = step * self.lr_peak / (self.n_steps * self.warmup_steps_part)\n            else:\n                self._lr = (self.n_steps - step) * self.lr_peak / (self.n_steps * (1 - self.warmup_steps_part))\n        return self._lr\n\n    def state_dict(self):\n        sd = copy.deepcopy(self.__dict__)\n        return sd\n\n    def load_state_dict(self, sd):\n        for k in sd.keys():\n            self.__setattr__(k, sd[k])","metadata":{"id":"YDvKYF5EAdnX","execution":{"iopub.status.busy":"2023-04-12T12:18:54.028020Z","iopub.execute_input":"2023-04-12T12:18:54.028401Z","iopub.status.idle":"2023-04-12T12:18:54.039114Z","shell.execute_reply.started":"2023-04-12T12:18:54.028373Z","shell.execute_reply":"2023-04-12T12:18:54.037912Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def test_lr_scheduler():\n    lrs_type = 'warmup,decay_linear'\n    warmup_steps_part =  0.1\n    lr_peak = 3e-4\n    sch = LrScheduler(100, type=lrs_type, warmup_steps_part=warmup_steps_part,\n                      lr_peak=lr_peak)\n    assert sch.learning_rate(step=5) - 15e-5 < 1e-6\n    assert sch.learning_rate(step=10) - 3e-4 < 1e-6\n    assert sch.learning_rate(step=50) - 166e-6 < 1e-6\n    assert sch.learning_rate(step=100) - 0. < 1e-6\n    print('Test is passed!')","metadata":{"id":"4JHOgJDBGjhr","execution":{"iopub.status.busy":"2023-04-12T12:18:54.041957Z","iopub.execute_input":"2023-04-12T12:18:54.042263Z","iopub.status.idle":"2023-04-12T12:18:54.052383Z","shell.execute_reply.started":"2023-04-12T12:18:54.042235Z","shell.execute_reply":"2023-04-12T12:18:54.051266Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"test_lr_scheduler()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H2Ys4DZRGmzM","outputId":"6cf0a0ba-e7f4-49ee-9106-96b4c39eb2c8","execution":{"iopub.status.busy":"2023-04-12T12:18:54.054122Z","iopub.execute_input":"2023-04-12T12:18:54.054756Z","iopub.status.idle":"2023-04-12T12:18:54.063048Z","shell.execute_reply.started":"2023-04-12T12:18:54.054716Z","shell.execute_reply":"2023-04-12T12:18:54.060968Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Test is passed!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Run and translate","metadata":{"id":"byCY6Tn-A9i_"}},{"cell_type":"code","source":"def format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    elapsed_rounded = int(round((elapsed)))\n    return str(datetime.timedelta(seconds=elapsed_rounded))\n\n\ndef run_epoch(data_iter, model, lr_scheduler, optimizer, device, verbose=False, lbl_smooth=0):\n    start = time.time()\n    local_start = start\n    total_tokens = 0\n    total_loss = 0\n    tokens = 0\n    loss_fn = nn.CrossEntropyLoss(reduction='sum', label_smoothing=lbl_smooth)\n    for i, batch in enumerate(data_iter):\n        encoder_input = batch[0].to(device)\n        decoder_input = batch[1].to(device)\n        decoder_target = batch[2].to(device)\n        logits = model(encoder_input, decoder_input)\n        loss = loss_fn(logits.view(-1, model.tgt_vocab_size),\n                       decoder_target.view(-1))\n        total_loss += loss.item()\n        batch_n_tokens = (decoder_target != model.pad_idx).sum().item()\n        total_tokens += batch_n_tokens\n        if optimizer is not None:\n            optimizer.zero_grad()\n            lr_scheduler.step(optimizer)\n            loss.backward()\n            optimizer.step()\n\n        tokens += batch_n_tokens\n        if verbose and i % 1000 == 1:\n            elapsed = time.time() - local_start\n            print(\"batch number: %d, accumulated average loss: %f, tokens per second: %f\" %\n                  (i, total_loss / total_tokens, tokens / elapsed))\n            local_start = time.time()\n            tokens = 0\n\n    average_loss = total_loss / total_tokens\n    print('** End of epoch, accumulated average loss = %f **' % average_loss)\n    epoch_elapsed_time = format_time(time.time() - start)\n    print(f'** Elapsed time: {epoch_elapsed_time}**')\n    return average_loss\n\n\ndef save_checkpoint(epoch, model, lr_scheduler, optimizer, model_dir_path):\n    save_path = os.path.join(model_dir_path, f'cpkt_{epoch}_epoch')\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'lr_scheduler_state_dict': lr_scheduler.state_dict()\n    }, save_path)\n    print(f'Saved checkpoint to {save_path}')\n\ndef load_model(epoch, model_dir_path):\n    save_path = os.path.join(model_dir_path, f'cpkt_{epoch}_epoch')\n    checkpoint = torch.load(save_path)\n    with open(os.path.join(model_dir_path, 'model_config.json'), 'r', encoding='utf-8') as rf:\n        model_config = json.load(rf)\n    model = prepare_model(model_config)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    return model\n\ndef greedy_decode(model, device, encoder_input, max_len, start_symbol):\n    batch_size = encoder_input.size()[0]\n    decoder_input = torch.ones(batch_size, 1).fill_(start_symbol).type_as(encoder_input.data).to(device)\n\n    for i in range(max_len):\n        logits = model(encoder_input, decoder_input)\n\n        _, predicted_ids = torch.max(logits, dim=-1)\n        next_word = predicted_ids[:, i]\n        # print(next_word)\n        rest = torch.ones(batch_size, 1).type_as(decoder_input.data)\n        # print(rest[:,0].size(), next_word.size())\n        rest[:, 0] = next_word\n        decoder_input = torch.cat([decoder_input, rest], dim=1).to(device)\n        # print(decoder_input)\n    return decoder_input\n\ndef generate_predictions(dataloader, max_decoding_len, text_encoder, model, device):\n    # print(f'Max decoding length = {max_decoding_len}')\n    model.eval()\n    predictions = []\n    start_token_id = text_encoder.service_vocabs['token2id'][\n        text_encoder.service_token_names['start_token']]\n    with torch.no_grad():\n        for batch in tqdm(dataloader):\n            encoder_input = batch[0].to(device)\n            prediction_tensor = \\\n                greedy_decode(model, device, encoder_input, max_decoding_len,\n                              start_token_id)\n\n            predictions.extend([''.join(e) for e in text_encoder.id2token(prediction_tensor.cpu().numpy(),\n                                                                          unframe=True, lang_key='ru')])\n    return np.array(predictions)\n\n\ndef train(source_strings, target_strings, dropout=0.1, lr=3e-4, lbl_smooth=0, n_epochs=100):\n    '''Common training cycle for final run (fixed hyperparameters,\n    no evaluation during training)'''\n    if torch.cuda.is_available():\n        device = torch.device('cuda')\n        print(f'Using GPU device: {device}')\n    else:\n        device = torch.device('cpu')\n        print(f'GPU is not available, using CPU device {device}')\n\n    train_df = pd.DataFrame({'en': source_strings, 'ru': target_strings})\n    text_encoder = TextEncoder()\n    text_encoder.make_vocabs(train_df)\n\n    model_config = {\n        'src_vocab_size': text_encoder.src_vocab_size,\n        'tgt_vocab_size': text_encoder.tgt_vocab_size,\n        'max_src_seq_length': max(train_df['en'].aggregate(len)) + 2, #including start_token and end_token\n        'max_tgt_seq_length': max(train_df['ru'].aggregate(len)) + 2,\n        'n_layers': 2,\n        'n_heads': 2,\n        'hidden_size': 128,\n        'ff_hidden_size': 256,\n        'dropout': {\n            'embedding': dropout,\n            'attention': dropout,\n            'residual': dropout,\n            'relu': dropout\n        },\n        'pad_idx': 0\n    }\n    torch.save(model_config, 'model_config.json')\n    model = prepare_model(model_config)\n    model.to(device)\n\n    train_config = {'batch_size': 200, 'n_epochs': n_epochs, 'lr_scheduler': {\n        'type': 'warmup,decay_linear',\n        'warmup_steps_part': 0.1,\n        'lr_peak': lr,\n    }}\n\n    #Model training procedure\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.)\n    n_steps = (len(train_df) // train_config['batch_size'] + 1) * train_config['n_epochs']\n    lr_scheduler = LrScheduler(n_steps, **train_config['lr_scheduler'])\n\n    # prepare train data\n    source_strings, target_strings = zip(*sorted(zip(source_strings, target_strings),\n                                                 key=lambda e: len(e[0])))\n    train_dataloader = create_dataloader(source_strings, target_strings, text_encoder,\n                                         train_config['batch_size'],\n                                         shuffle_batches_each_epoch=True)\n    # training cycle\n    for epoch in tqdm(range(1,train_config['n_epochs']+1)):\n        #print('\\n' + '-'*40)\n        #print(f'Epoch: {epoch}')\n        #print(f'Run training...')\n        model.train()\n        run_epoch(train_dataloader, model,\n                  lr_scheduler, optimizer, device=device, verbose=False, lbl_smooth=lbl_smooth)\n        if epoch % 10 == 0:\n            save_checkpoint(epoch, model, lr_scheduler, optimizer, './model')\n    learnable_params = {\n        'model': model,\n        'text_encoder': text_encoder,\n    }\n    return learnable_params\n\ndef classify(source_strings, learnable_params):\n    if torch.cuda.is_available():\n        device = torch.device('cuda')\n        print(f'Using GPU device: {device}')\n    else:\n        device = torch.device('cpu')\n        print(f'GPU is not available, using CPU device {device}')\n\n    model = learnable_params['model']\n    text_encoder = learnable_params['text_encoder']\n    batch_size = 200\n    dataloader = create_dataloader(source_strings, None, text_encoder,\n                                   batch_size, shuffle_batches_each_epoch=False)\n    max_decoding_len = model.config['max_tgt_seq_length']\n    predictions = generate_predictions(dataloader, max_decoding_len, text_encoder, model, device)\n    #return single top1 prediction for each sample\n    return np.expand_dims(predictions, 1)","metadata":{"id":"-K7-KJEGA8po","execution":{"iopub.status.busy":"2023-04-12T12:18:54.064655Z","iopub.execute_input":"2023-04-12T12:18:54.065650Z","iopub.status.idle":"2023-04-12T12:18:54.097309Z","shell.execute_reply.started":"2023-04-12T12:18:54.065609Z","shell.execute_reply":"2023-04-12T12:18:54.096290Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{"id":"jpG6i8X-HMmF"}},{"cell_type":"code","source":"PREDS_FNAME = \"preds_translit.tsv\"\nSCORED_PARTS = ('train', 'dev', 'train_small', 'dev_small', 'test')\nTRANSLIT_PATH = \"TRANSLIT\"","metadata":{"id":"f-7-YtzEKnug","execution":{"iopub.status.busy":"2023-04-12T12:18:54.098864Z","iopub.execute_input":"2023-04-12T12:18:54.099403Z","iopub.status.idle":"2023-04-12T12:18:54.108328Z","shell.execute_reply.started":"2023-04-12T12:18:54.099341Z","shell.execute_reply":"2023-04-12T12:18:54.107268Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"!mkdir model","metadata":{"execution":{"iopub.status.busy":"2023-04-12T12:18:54.109675Z","iopub.execute_input":"2023-04-12T12:18:54.110108Z","iopub.status.idle":"2023-04-12T12:18:55.077686Z","shell.execute_reply.started":"2023-04-12T12:18:54.110070Z","shell.execute_reply":"2023-04-12T12:18:55.076329Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"top_k = 1\npart2ixy = load_dataset(TRANSLIT_PATH, parts=SCORED_PARTS)\ntrain_ids, train_strings, train_transliterations = part2ixy['train']\nprint('\\nTraining classifier on %d examples from train set ...' % len(train_strings))\nst = time.time()\nparams = train(train_strings, train_transliterations, n_epochs=600)\nprint('Classifier trained in %.2fs' % (time.time() - st))","metadata":{"id":"74GcLUTuLFyS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"99c31f45-6bc3-458c-9715-b1983676a7b6","execution":{"iopub.status.busy":"2023-04-12T12:18:55.079531Z","iopub.execute_input":"2023-04-12T12:18:55.079918Z","iopub.status.idle":"2023-04-12T12:18:55.577730Z","shell.execute_reply.started":"2023-04-12T12:18:55.079883Z","shell.execute_reply":"2023-04-12T12:18:55.576651Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"allpreds = []\n\nfor part, (ids, x, y) in part2ixy.items():\n    print('\\nClassifying %s set with %d examples ...' % (part, len(x)))\n    st = time.time()\n    preds = classify(x, params)\n    print('%s set classified in %.2fs' % (part, time.time() - st))\n    count_of_values = list(map(len, preds))\n    assert np.all(np.array(count_of_values) == top_k)\n    #score(preds, y)\n    allpreds.extend(zip(ids, preds))\n\nsave_preds(allpreds, preds_fname='b'+PREDS_FNAME)\nprint('\\nChecking saved predictions ...')\nscore_preds(preds_path='b'+PREDS_FNAME, data_dir=TRANSLIT_PATH, parts=SCORED_PARTS)","metadata":{"id":"hPELZcXeHLHF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bed82695-5b39-445c-ec9d-e293f8e69fc9","execution":{"iopub.status.busy":"2023-04-11T22:01:14.337290Z","iopub.execute_input":"2023-04-11T22:01:14.338230Z","iopub.status.idle":"2023-04-11T22:02:57.700823Z","shell.execute_reply.started":"2023-04-11T22:01:14.338178Z","shell.execute_reply":"2023-04-11T22:02:57.699720Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/527 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dfbc98f9e2a4979b245bb39f7f50977"}},"metadata":{}},{"name":"stdout","text":"train set classified in 63.25s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eac15e05235642cfb8203968c16053eb"}},"metadata":{}},{"name":"stdout","text":"dev set classified in 16.38s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c51a6de7401640149d2d19018a22a044"}},"metadata":{}},{"name":"stdout","text":"train_small set classified in 1.20s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24db300cee65492a8adb97822f7ea6f1"}},"metadata":{}},{"name":"stdout","text":"dev_small set classified in 1.20s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/165 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76aadd7ea688494bb9efce10e7ad61e5"}},"metadata":{}},{"name":"stdout","text":"test set classified in 19.43s\nPredictions saved to bpreds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.73\ndev set accuracy@1: 0.67\ntrain_small set accuracy@1: 0.73\ndev_small set accuracy@1: 0.69\nno labels for test set\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"{'train': {'acc@1': 0.7309980924542806},\n 'dev': {'acc@1': 0.673145547035153},\n 'train_small': {'acc@1': 0.7285},\n 'dev_small': {'acc@1': 0.69}}"},"metadata":{}}]},{"cell_type":"markdown","source":"###  Hyper-parameters choice","metadata":{"id":"oFfDH0-SsRm-"}},{"cell_type":"markdown","source":"The model is ready. Now we need to find the optimal hyper-parameters.\n\nThe quality of models with different hyperparameters should be monitored on dev or on dev_small samples (in order to save time, since generating transliterations is a rather time-consuming process, comparable to one training epoch).\n\nTo generate predictions, you can use the `generate_predictions` function, to calculate the accuracy@1 metric, and then you can use the `compute_metrics` function.\n\n\n\nHyper-parameters are stored in the dictionary `model_config` and `train_config` in train function. The following hyperparameters in `model_config` and `train_config` are suggested to leave unmodified:\n\n* n_layers $=$ 2\n* n_heads $=$ 2\n* hidden_size $=$ 128\n* fc_hidden_size $=$ 256\n* warmup_steps_part $=$ 0.1\n* batch_size $=$ 200\n\n You can vary the dropout value. The model has 4 types of : ***embedding dropout*** applied on embdeddings before sending to the first layer of  Encoder or Decoder, ***attention*** dropout applied on the attention weights in the MultiHeadAttention layer, ***residual dropout*** applied on the output of each sublayer (MultiHeadAttention or FeedForward) in layers Encoder and Decoder and, finaly, ***relu dropout*** in used in FeedForward layer. For all 4 types it is suggested to test the same value of dropout from the list: 0.1, 0.15, 0.2.\n Also it is suggested to test several peak levels of learning rate - **lr_peak** : 5e-4, 1e-3, 2e-3.\n\nNote that if you are using a GPU, then training one epoch takes about 1 minute, and up to 1 GB of video memory is required. When using the CPU, the learning speed slows down by about 2 times. If there are problems with insufficient RAM / video memory, reduce the batch size, but in this case the optimal range of learning rate values will change, and it must be determined again. To train a model with  batch_size $=$ 200 , it will take at least 300 epochs to achieve accuracy 0.66 on dev_small dataset.","metadata":{"id":"PxqZbEmtsV0g"}},{"cell_type":"markdown","source":"*Question: What are the optimal hyperpameters according to your experiments? Add plots or other descriptions here.* \n\n```\n\nOptimal hyperparameters are dropout_rate=0.1, lr_peak=2e-3, according to results of grid search.\n\n```\n\n","metadata":{"id":"IQXVmzk0a60Y"}},{"cell_type":"code","source":"all_scores = {}\n# top_k = 1\n# part2ixy = load_dataset(TRANSLIT_PATH, parts=SCORED_PARTS)\n# train_ids, train_strings, train_transliterations = part2ixy['train']\nfor dropout in [0.1, 0.15, 0.2]:\n    for lr_peak in [5e-4, 1e-3, 2e-3]:\n        params = train(train_strings, train_transliterations, dropout, lr_peakб n_epochs=50)\n        allpreds = []\n        for part, (ids, x, y) in part2ixy.items():\n            print('\\nClassifying %s set with %d examples ...' % (part, len(x)))\n            st = time.time()\n            preds = classify(x, params)\n            print('%s set classified in %.2fs' % (part, time.time() - st))\n            count_of_values = list(map(len, preds))\n            assert np.all(np.array(count_of_values) == top_k)\n            #score(preds, y)\n            allpreds.extend(zip(ids, preds))\n\n        save_preds(allpreds, preds_fname=str(dropout) + str(lr_peak) + PREDS_FNAME)\n        print('\\nChecking saved predictions ...')\n        all_scores[(dropout, lr_peak)] = score_preds(preds_path=str(dropout) + str(lr_peak) + PREDS_FNAME, data_dir=TRANSLIT_PATH, parts=SCORED_PARTS)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":640},"id":"vvt4uvB2VjuD","outputId":"68f22587-de5c-4759-8c0d-34b2ba200aeb","execution":{"iopub.status.busy":"2023-04-07T11:16:46.691510Z","iopub.execute_input":"2023-04-07T11:16:46.691876Z","iopub.status.idle":"2023-04-07T13:31:36.913862Z","shell.execute_reply.started":"2023-04-07T11:16:46.691843Z","shell.execute_reply":"2023-04-07T13:31:36.912662Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Using GPU device: cuda\n\n----------------------------------------\nEpoch: 1\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 4.124072 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 2\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 2.677284 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 3\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 31.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 1.324125 **\n** Elapsed time: 0:00:17**\n\n----------------------------------------\nEpoch: 4\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.918346 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 5\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.745543 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 6\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.632124 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 7\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 31.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.569391 **\n** Elapsed time: 0:00:17**\n\n----------------------------------------\nEpoch: 8\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.532438 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 9\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 31.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.507071 **\n** Elapsed time: 0:00:17**\n\n----------------------------------------\nEpoch: 10\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.483048 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_10_epoch\n\n----------------------------------------\nEpoch: 11\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 31.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.460715 **\n** Elapsed time: 0:00:17**\n\n----------------------------------------\nEpoch: 12\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.440129 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 13\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.422338 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 14\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.407841 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 15\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.397976 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 16\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.387813 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 17\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.380402 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 18\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.373454 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 19\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.366412 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 20\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.360379 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_20_epoch\n\n----------------------------------------\nEpoch: 21\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.355499 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 22\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.351313 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 23\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.346916 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 24\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:19, 27.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.342712 **\n** Elapsed time: 0:00:19**\n\n----------------------------------------\nEpoch: 25\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.339434 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 26\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.336639 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 27\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.332926 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 28\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.329893 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 29\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.326767 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 30\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 31.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.324629 **\n** Elapsed time: 0:00:17**\nSaved checkpoint to ./model/cpkt_30_epoch\n\n----------------------------------------\nEpoch: 31\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.321961 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 32\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.319763 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 33\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.317660 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 34\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.314371 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 35\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.312471 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 36\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.311259 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 37\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 31.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.309268 **\n** Elapsed time: 0:00:17**\n\n----------------------------------------\nEpoch: 38\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.307883 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 39\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.306092 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 40\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.305001 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_40_epoch\n\n----------------------------------------\nEpoch: 41\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.303030 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 42\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.302347 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 43\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.300725 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 44\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.298864 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 45\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.298804 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 46\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.298269 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 47\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.296863 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 48\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.296562 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 49\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.295670 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 50\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.294956 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_50_epoch\n\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 527/527 [01:03<00:00,  8.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"train set classified in 63.82s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 132/132 [00:16<00:00,  8.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev set classified in 16.22s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_small set classified in 1.16s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev_small set classified in 1.16s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 165/165 [00:19<00:00,  8.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"test set classified in 19.58s\nPredictions saved to 0.10.0005preds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.65\ndev set accuracy@1: 0.63\ntrain_small set accuracy@1: 0.65\ndev_small set accuracy@1: 0.65\nno labels for test set\nUsing GPU device: cuda\n\n----------------------------------------\nEpoch: 1\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 3.731054 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 2\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 1.981639 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 3\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.942566 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 4\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.707493 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 5\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.594345 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 6\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.530846 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 7\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.491571 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 8\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.462492 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 9\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.437567 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 10\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.418270 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_10_epoch\n\n----------------------------------------\nEpoch: 11\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.409257 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 12\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.391933 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 13\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.383296 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 14\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.373648 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 15\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.366513 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 16\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.359512 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 17\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.352973 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 18\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.346925 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 19\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.341887 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 20\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.337951 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_20_epoch\n\n----------------------------------------\nEpoch: 21\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.333680 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 22\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.328886 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 23\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.324305 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 24\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.320351 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 25\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.316434 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 26\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.313763 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 27\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.310729 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 28\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.307162 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 29\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.304721 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 30\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.302635 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_30_epoch\n\n----------------------------------------\nEpoch: 31\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.299749 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 32\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.297632 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 33\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.293862 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 34\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.292689 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 35\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.290265 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 36\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.288433 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 37\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.285974 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 38\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.284436 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 39\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.281887 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 40\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.280245 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_40_epoch\n\n----------------------------------------\nEpoch: 41\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.278049 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 42\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.276621 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 43\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.274890 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 44\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.273473 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 45\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.271386 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 46\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.270302 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 47\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.268882 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 48\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.267092 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 49\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.266473 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 50\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.266048 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_50_epoch\n\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 527/527 [01:02<00:00,  8.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"train set classified in 62.75s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 132/132 [00:15<00:00,  8.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev set classified in 15.41s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_small set classified in 1.16s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev_small set classified in 1.15s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 165/165 [00:19<00:00,  8.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"test set classified in 19.72s\nPredictions saved to 0.10.001preds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.67\ndev set accuracy@1: 0.65\ntrain_small set accuracy@1: 0.68\ndev_small set accuracy@1: 0.66\nno labels for test set\nUsing GPU device: cuda\n\n----------------------------------------\nEpoch: 1\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 3.458621 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 2\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 1.266245 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 3\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.745397 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 4\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.583726 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 5\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.520814 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 6\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.477410 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 7\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.443552 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 8\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.423382 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 9\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.409271 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 10\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.394339 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_10_epoch\n\n----------------------------------------\nEpoch: 11\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.394162 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 12\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.377190 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 13\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.368293 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 14\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.363730 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 15\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.356993 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 16\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.350211 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 17\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.346011 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 18\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.339045 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 19\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.334846 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 20\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.329721 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_20_epoch\n\n----------------------------------------\nEpoch: 21\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.325397 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 22\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.321950 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 23\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.317826 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 24\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.315093 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 25\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.310714 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 26\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.307249 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 27\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.304121 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 28\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.300653 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 29\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.297370 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 30\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.295060 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_30_epoch\n\n----------------------------------------\nEpoch: 31\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.290912 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 32\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.289408 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 33\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.285450 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 34\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.283183 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 35\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.280508 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 36\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.277423 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 37\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.275377 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 38\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.271905 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 39\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.270034 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 40\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.267798 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_40_epoch\n\n----------------------------------------\nEpoch: 41\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.265831 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 42\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.263621 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 43\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.260941 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 44\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.259170 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 45\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.256650 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 46\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.255091 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 47\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.252659 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 48\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.251381 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 49\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.249377 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 50\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.247928 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_50_epoch\n\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 527/527 [01:02<00:00,  8.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"train set classified in 62.23s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 132/132 [00:15<00:00,  8.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev set classified in 15.73s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_small set classified in 1.14s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev_small set classified in 1.16s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 165/165 [00:19<00:00,  8.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"test set classified in 19.50s\nPredictions saved to 0.10.002preds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.69\ndev set accuracy@1: 0.66\ntrain_small set accuracy@1: 0.68\ndev_small set accuracy@1: 0.68\nno labels for test set\nUsing GPU device: cuda\n\n----------------------------------------\nEpoch: 1\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 4.131675 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 2\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 2.817931 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 3\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 1.735268 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 4\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 1.090536 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 5\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.880416 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 6\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.737292 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 7\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.651249 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 8\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.604316 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 9\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.569617 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 10\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.544036 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_10_epoch\n\n----------------------------------------\nEpoch: 11\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.524168 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 12\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.501846 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 13\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.487063 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 14\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.469034 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 15\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.456211 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 16\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.444706 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 17\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.433093 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 18\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.425052 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 19\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.416901 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 20\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.410265 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_20_epoch\n\n----------------------------------------\nEpoch: 21\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.405199 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 22\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.399263 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 23\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.394015 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 24\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.389288 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 25\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.385483 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 26\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.380792 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 27\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.377815 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 28\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.374022 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 29\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.371040 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 30\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.367425 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_30_epoch\n\n----------------------------------------\nEpoch: 31\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.364181 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 32\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.361982 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 33\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.359879 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 34\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.357226 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 35\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.355375 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 36\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.353039 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 37\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.351046 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 38\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.348630 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 39\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.347639 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 40\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.346299 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_40_epoch\n\n----------------------------------------\nEpoch: 41\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.344817 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 42\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.342854 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 43\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.342428 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 44\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.341122 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 45\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.339174 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 46\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.338301 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 47\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.336240 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 48\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.336406 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 49\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.336265 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 50\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.335944 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_50_epoch\n\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 527/527 [01:02<00:00,  8.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"train set classified in 62.52s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 132/132 [00:15<00:00,  8.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev set classified in 15.29s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_small set classified in 1.21s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev_small set classified in 1.19s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 165/165 [00:19<00:00,  8.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"test set classified in 19.45s\nPredictions saved to 0.150.0005preds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.62\ndev set accuracy@1: 0.61\ntrain_small set accuracy@1: 0.63\ndev_small set accuracy@1: 0.64\nno labels for test set\nUsing GPU device: cuda\n\n----------------------------------------\nEpoch: 1\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 3.811090 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 2\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 2.286257 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 3\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 1.123287 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 4\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.848072 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 5\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.715024 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 6\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.635280 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 7\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.580173 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 8\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.537207 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 9\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.498608 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 10\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.473564 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_10_epoch\n\n----------------------------------------\nEpoch: 11\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.454410 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 12\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.438937 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 13\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.425538 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 14\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.418364 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 15\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.407798 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 16\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.398296 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 17\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.391419 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 18\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.387084 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 19\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.379983 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 20\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.374631 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_20_epoch\n\n----------------------------------------\nEpoch: 21\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.369795 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 22\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.366356 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 23\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.361192 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 24\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.357573 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 25\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.353920 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 26\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.350588 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 27\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.346452 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 28\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.344299 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 29\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.341135 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 30\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.337844 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_30_epoch\n\n----------------------------------------\nEpoch: 31\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.335391 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 32\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.332957 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 33\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.329912 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 34\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.328330 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 35\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.325867 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 36\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.323647 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 37\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.321723 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 38\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.318941 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 39\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.318564 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 40\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.316137 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_40_epoch\n\n----------------------------------------\nEpoch: 41\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.314068 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 42\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.312742 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 43\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.310615 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 44\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.309271 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 45\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.307884 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 46\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.306622 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 47\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.304972 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 48\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.303942 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 49\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.302275 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 50\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.301942 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_50_epoch\n\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 527/527 [01:02<00:00,  8.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"train set classified in 62.61s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 132/132 [00:15<00:00,  8.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev set classified in 15.73s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_small set classified in 1.16s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev_small set classified in 1.15s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 165/165 [00:19<00:00,  8.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"test set classified in 19.73s\nPredictions saved to 0.150.001preds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.65\ndev set accuracy@1: 0.63\ntrain_small set accuracy@1: 0.65\ndev_small set accuracy@1: 0.64\nno labels for test set\nUsing GPU device: cuda\n\n----------------------------------------\nEpoch: 1\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 3.463174 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 2\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 1.510653 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 3\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.883528 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 4\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.672055 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 5\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.599654 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 6\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.549575 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 7\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.513689 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 8\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.487508 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 9\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.469783 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 10\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.445332 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_10_epoch\n\n----------------------------------------\nEpoch: 11\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.436772 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 12\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.424028 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 13\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.413117 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 14\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.406180 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 15\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.399016 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 16\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.391211 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 17\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.384716 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 18\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.379012 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 19\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.374538 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 20\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.369284 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_20_epoch\n\n----------------------------------------\nEpoch: 21\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.364739 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 22\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.362213 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 23\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.356870 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 24\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.352857 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 25\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.348837 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 26\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 31.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.344682 **\n** Elapsed time: 0:00:17**\n\n----------------------------------------\nEpoch: 27\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.342290 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 28\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.338614 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 29\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.335295 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 30\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.331707 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_30_epoch\n\n----------------------------------------\nEpoch: 31\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.329219 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 32\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.326233 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 33\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.324318 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 34\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.320805 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 35\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.318726 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 36\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.315153 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 37\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.313626 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 38\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.309453 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 39\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.308357 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 40\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.305996 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_40_epoch\n\n----------------------------------------\nEpoch: 41\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.303929 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 42\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.301823 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 43\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.299815 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 44\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.297527 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 45\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.294932 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 46\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.294090 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 47\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.291477 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 48\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.288917 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 49\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.288268 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 50\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.287510 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_50_epoch\n\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 527/527 [01:02<00:00,  8.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"train set classified in 63.04s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 132/132 [00:15<00:00,  8.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev set classified in 15.88s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_small set classified in 1.20s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev_small set classified in 1.25s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 165/165 [00:19<00:00,  8.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"test set classified in 19.44s\nPredictions saved to 0.150.002preds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.66\ndev set accuracy@1: 0.64\ntrain_small set accuracy@1: 0.65\ndev_small set accuracy@1: 0.65\nno labels for test set\nUsing GPU device: cuda\n\n----------------------------------------\nEpoch: 1\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 31.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 4.109860 **\n** Elapsed time: 0:00:17**\n\n----------------------------------------\nEpoch: 2\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 2.955043 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 3\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 2.035546 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 4\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 1.268178 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 5\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 31.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 1.022659 **\n** Elapsed time: 0:00:17**\n\n----------------------------------------\nEpoch: 6\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.866334 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 7\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.756172 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 8\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.684861 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 9\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.643006 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 10\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.609100 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_10_epoch\n\n----------------------------------------\nEpoch: 11\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.584625 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 12\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.565301 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 13\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.546789 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 14\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.532714 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 15\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.519010 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 16\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 31.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.507408 **\n** Elapsed time: 0:00:17**\n\n----------------------------------------\nEpoch: 17\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.496739 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 18\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.486611 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 19\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.476806 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 20\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.467255 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_20_epoch\n\n----------------------------------------\nEpoch: 21\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.459423 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 22\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.452441 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 23\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.445493 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 24\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.439312 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 25\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.434379 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 26\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.429963 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 27\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.426472 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 28\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.421280 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 29\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.417950 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 30\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.413330 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_30_epoch\n\n----------------------------------------\nEpoch: 31\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.409999 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 32\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.408951 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 33\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.405170 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 34\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.402184 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 35\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.399458 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 36\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.398134 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 37\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.396098 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 38\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.393795 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 39\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.393145 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 40\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.390227 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_40_epoch\n\n----------------------------------------\nEpoch: 41\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.388624 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 42\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.387148 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 43\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.385155 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 44\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.383251 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 45\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.382270 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 46\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.382225 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 47\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.381253 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 48\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.380271 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 49\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.379283 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 50\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.379511 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_50_epoch\n\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 527/527 [01:02<00:00,  8.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"train set classified in 62.77s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 132/132 [00:15<00:00,  8.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev set classified in 15.35s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  7.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_small set classified in 1.34s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  6.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev_small set classified in 1.50s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 165/165 [00:19<00:00,  8.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"test set classified in 19.30s\nPredictions saved to 0.20.0005preds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.60\ndev set accuracy@1: 0.59\ntrain_small set accuracy@1: 0.60\ndev_small set accuracy@1: 0.61\nno labels for test set\nUsing GPU device: cuda\n\n----------------------------------------\nEpoch: 1\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 3.830605 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 2\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 2.637706 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 3\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 31.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 1.404487 **\n** Elapsed time: 0:00:17**\n\n----------------------------------------\nEpoch: 4\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.996687 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 5\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 31.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.800938 **\n** Elapsed time: 0:00:17**\n\n----------------------------------------\nEpoch: 6\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.687409 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 7\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 31.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.626321 **\n** Elapsed time: 0:00:17**\n\n----------------------------------------\nEpoch: 8\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.586446 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 9\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.560392 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 10\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.538876 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_10_epoch\n\n----------------------------------------\nEpoch: 11\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.518630 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 12\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.501016 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 13\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.486066 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 14\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.471395 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 15\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.459044 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 16\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.453248 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 17\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.442752 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 18\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.434163 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 19\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.426374 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 20\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.419917 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_20_epoch\n\n----------------------------------------\nEpoch: 21\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.414269 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 22\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.410196 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 23\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.404280 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 24\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.401562 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 25\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.396467 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 26\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.393232 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 27\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.389004 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 28\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.386691 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 29\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.382978 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 30\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.380075 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_30_epoch\n\n----------------------------------------\nEpoch: 31\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.377146 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 32\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.374643 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 33\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.372424 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 34\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.369691 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 35\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.366696 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 36\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.366293 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 37\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.363156 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 38\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.360763 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 39\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.358205 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 40\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.356867 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_40_epoch\n\n----------------------------------------\nEpoch: 41\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.355434 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 42\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.353590 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 43\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.352369 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 44\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.351167 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 45\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.348883 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 46\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.347688 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 47\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.346820 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 48\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.345095 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 49\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.343400 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 50\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.343442 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_50_epoch\n\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 527/527 [01:02<00:00,  8.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"train set classified in 62.64s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 132/132 [00:15<00:00,  8.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev set classified in 15.50s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_small set classified in 1.16s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev_small set classified in 1.17s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 165/165 [00:19<00:00,  8.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"test set classified in 19.80s\nPredictions saved to 0.20.001preds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.62\ndev set accuracy@1: 0.61\ntrain_small set accuracy@1: 0.63\ndev_small set accuracy@1: 0.63\nno labels for test set\nUsing GPU device: cuda\n\n----------------------------------------\nEpoch: 1\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 3.681346 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 2\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 1.964511 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 3\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 1.047629 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 4\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.782669 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 5\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.675829 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 6\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.615300 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 7\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.579669 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 8\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.556071 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 9\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.534743 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 10\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.511391 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_10_epoch\n\n----------------------------------------\nEpoch: 11\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.497857 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 12\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.491571 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 13\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.472895 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 14\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.462515 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 15\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.453894 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 16\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.444875 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 17\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.440976 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 18\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.431794 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 19\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.422999 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 20\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.419181 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_20_epoch\n\n----------------------------------------\nEpoch: 21\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.413963 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 22\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.410271 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 23\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.404651 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 24\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.401086 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 25\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.396203 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 26\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.392579 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 27\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 32.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.389184 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 28\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.384881 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 29\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.382429 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 30\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.379109 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_30_epoch\n\n----------------------------------------\nEpoch: 31\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.374613 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 32\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.372438 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 33\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.368202 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 34\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.364997 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 35\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.363518 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 36\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.361100 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 37\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.357216 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 38\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 34.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.355318 **\n** Elapsed time: 0:00:15**\n\n----------------------------------------\nEpoch: 39\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.353196 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 40\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.350558 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_40_epoch\n\n----------------------------------------\nEpoch: 41\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.347476 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 42\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.344661 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 43\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.343481 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 44\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.340333 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 45\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.338680 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 46\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.336844 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 47\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.333860 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 48\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.332754 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 49\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:16, 32.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.331726 **\n** Elapsed time: 0:00:16**\n\n----------------------------------------\nEpoch: 50\nRun training...\n","output_type":"stream"},{"name":"stderr","text":"527it [00:15, 33.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"** End of epoch, accumulated average loss = 0.330752 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_50_epoch\n\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 527/527 [01:02<00:00,  8.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"train set classified in 62.31s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 132/132 [00:16<00:00,  8.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev set classified in 16.07s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_small set classified in 1.16s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev_small set classified in 1.16s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 165/165 [00:19<00:00,  8.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"test set classified in 19.40s\nPredictions saved to 0.20.002preds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.63\ndev set accuracy@1: 0.61\ntrain_small set accuracy@1: 0.63\ndev_small set accuracy@1: 0.64\nno labels for test set\n","output_type":"stream"}]},{"cell_type":"code","source":"for k,v in all_scores.items():\n    print(k, v['dev'])","metadata":{"execution":{"iopub.status.busy":"2023-04-07T13:32:30.479969Z","iopub.execute_input":"2023-04-07T13:32:30.480474Z","iopub.status.idle":"2023-04-07T13:32:30.487922Z","shell.execute_reply.started":"2023-04-07T13:32:30.480388Z","shell.execute_reply":"2023-04-07T13:32:30.486748Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"(0.1, 0.0005) {'acc@1': 0.6293371801685521}\n(0.1, 0.001) {'acc@1': 0.6464960898944652}\n(0.1, 0.002) {'acc@1': 0.6581504821198086}\n(0.15, 0.0005) {'acc@1': 0.6108875559942297}\n(0.15, 0.001) {'acc@1': 0.6297927264444613}\n(0.15, 0.002) {'acc@1': 0.6357148280312809}\n(0.2, 0.0005) {'acc@1': 0.590767595474907}\n(0.2, 0.001) {'acc@1': 0.6100144256320704}\n(0.2, 0.002) {'acc@1': 0.6127097410978666}\n","output_type":"stream"}]},{"cell_type":"code","source":"params = train(train_strings, train_transliterations, dropout=0.1, lr=2e-3, n_epochs=600)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T12:18:55.581566Z","iopub.execute_input":"2023-04-12T12:18:55.581886Z","iopub.status.idle":"2023-04-12T14:50:27.086560Z","shell.execute_reply.started":"2023-04-12T12:18:55.581855Z","shell.execute_reply":"2023-04-12T14:50:27.085350Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Using GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/600 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fecaf982bc84352b78f2402df12c763"}},"metadata":{}},{"name":"stdout","text":"** End of epoch, accumulated average loss = 4.350479 **\n** Elapsed time: 0:00:17**\n** End of epoch, accumulated average loss = 3.109269 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.630872 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.549635 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.095959 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.912433 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.781164 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.683153 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.614688 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.570366 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_10_epoch\n** End of epoch, accumulated average loss = 0.533510 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.506842 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.483422 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.457660 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.441121 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.423163 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.409752 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.400176 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.392014 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.385239 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_20_epoch\n** End of epoch, accumulated average loss = 0.384170 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.372082 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.365351 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.361805 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.358410 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.358110 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.350549 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.347152 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.343681 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.343725 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_30_epoch\n** End of epoch, accumulated average loss = 0.340357 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.337568 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.336297 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.336158 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.333671 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.330640 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.331237 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.328746 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.329634 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.325968 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_40_epoch\n** End of epoch, accumulated average loss = 0.326452 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.325426 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.324036 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.325695 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.322180 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.322868 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.329051 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.323190 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.324216 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.320739 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_50_epoch\n** End of epoch, accumulated average loss = 0.322688 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.319227 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.321514 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.320439 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.320052 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.322139 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.320302 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.319411 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.322145 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.322888 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_60_epoch\n** End of epoch, accumulated average loss = 0.320140 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.319200 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.318339 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.316390 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.316507 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.315352 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.314818 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.310855 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.314003 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.312336 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_70_epoch\n** End of epoch, accumulated average loss = 0.310389 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.310386 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.311720 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.309909 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.306738 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.306549 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.308123 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.305811 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.305759 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.303774 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_80_epoch\n** End of epoch, accumulated average loss = 0.303461 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.304752 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.304100 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.304950 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.301959 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.300570 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.300973 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.300325 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.299760 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.299645 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_90_epoch\n** End of epoch, accumulated average loss = 0.299749 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.299432 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.297207 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.297723 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.300133 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.298025 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.296731 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.295589 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.294859 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.296677 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_100_epoch\n** End of epoch, accumulated average loss = 0.297607 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.296049 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.296342 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.292691 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.294466 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.293044 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.292672 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.292100 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.293457 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.291920 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_110_epoch\n** End of epoch, accumulated average loss = 0.291911 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.293764 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.290537 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.291269 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.288879 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.291962 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.291454 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.287966 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.287807 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.289447 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_120_epoch\n** End of epoch, accumulated average loss = 0.288747 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.288605 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.287273 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.288163 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.288386 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.286109 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.285779 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.284353 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.287319 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.285898 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_130_epoch\n** End of epoch, accumulated average loss = 0.285594 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.285474 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.286771 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.284800 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.283529 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.283685 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.282420 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.286524 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.284041 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.282045 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_140_epoch\n** End of epoch, accumulated average loss = 0.284076 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.284108 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.285281 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.283630 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.282763 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.280516 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.283008 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.279307 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.281500 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.281702 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_150_epoch\n** End of epoch, accumulated average loss = 0.281174 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.281539 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.279344 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.278217 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.278233 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.281500 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.281616 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.279587 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.280438 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.279710 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_160_epoch\n** End of epoch, accumulated average loss = 0.277546 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.279293 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.277165 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.276776 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.280286 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.278780 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.277477 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.276633 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.274745 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.277724 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_170_epoch\n** End of epoch, accumulated average loss = 0.277609 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.276770 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.276862 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.276226 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.276774 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.275142 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.274833 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.276089 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.275460 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.271392 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_180_epoch\n** End of epoch, accumulated average loss = 0.272768 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.275650 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.277205 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.274880 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.275107 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.271942 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.272344 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.272478 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.271961 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.273957 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_190_epoch\n** End of epoch, accumulated average loss = 0.272326 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.271735 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.272514 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.276236 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.272013 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.270351 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.269971 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.269842 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.269363 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.270475 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_200_epoch\n** End of epoch, accumulated average loss = 0.270677 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.268276 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.269746 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.269339 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.268461 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.269534 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.268103 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.267568 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.267626 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.268973 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_210_epoch\n** End of epoch, accumulated average loss = 0.268109 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.268569 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.267994 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.265651 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.266117 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.269692 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.268697 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.264573 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.267060 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.265359 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_220_epoch\n** End of epoch, accumulated average loss = 0.266598 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.265522 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.265516 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.266837 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.268616 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.265952 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.263874 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.265369 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.263969 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.263325 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_230_epoch\n** End of epoch, accumulated average loss = 0.268977 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.266108 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.264527 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.262721 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.261310 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.264041 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.262655 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.265034 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.261346 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.262788 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_240_epoch\n** End of epoch, accumulated average loss = 0.263540 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.262616 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.261048 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.261309 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.260340 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.261026 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.260928 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.260255 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.260275 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.260735 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_250_epoch\n** End of epoch, accumulated average loss = 0.259859 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.258660 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.258702 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.262100 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.262543 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.259067 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.259771 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.259728 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.259489 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.257948 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_260_epoch\n** End of epoch, accumulated average loss = 0.257627 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.258271 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.258361 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.257670 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.257056 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.258780 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.256783 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.262170 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.258221 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.255570 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_270_epoch\n** End of epoch, accumulated average loss = 0.254963 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.255463 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.255992 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.253862 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.255682 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.255946 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.255951 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.253840 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.253649 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.255712 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_280_epoch\n** End of epoch, accumulated average loss = 0.255110 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.254185 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.253144 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.253235 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.254766 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.256452 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.254967 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.253358 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.253032 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.252361 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_290_epoch\n** End of epoch, accumulated average loss = 0.253167 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.252565 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.253014 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.253154 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.251120 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.251574 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.250793 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.250856 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.250394 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.251380 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_300_epoch\n** End of epoch, accumulated average loss = 0.251545 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.251258 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.251188 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.251312 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.251101 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.252188 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.250079 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.249875 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.248221 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.247802 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_310_epoch\n** End of epoch, accumulated average loss = 0.247180 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.248506 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.248716 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.247473 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.248310 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.250012 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.248177 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.247468 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.246935 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.246923 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_320_epoch\n** End of epoch, accumulated average loss = 0.246106 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.246502 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.248474 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.247344 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.247238 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.245714 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.245788 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.246140 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.245651 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.244975 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_330_epoch\n** End of epoch, accumulated average loss = 0.244936 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.246140 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.244084 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.244406 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.243679 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.243791 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.243248 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.243919 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.243701 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.245168 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_340_epoch\n** End of epoch, accumulated average loss = 0.244405 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.242608 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.242906 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.243055 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.242186 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.241362 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.242904 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.241909 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.241820 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.243227 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_350_epoch\n** End of epoch, accumulated average loss = 0.242024 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.241008 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.240496 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.241013 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.241778 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.239594 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.240083 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.240889 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.240272 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.240104 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_360_epoch\n** End of epoch, accumulated average loss = 0.239762 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.239798 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.238874 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.239383 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.238919 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.239810 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.237714 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.237806 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.237695 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.238698 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_370_epoch\n** End of epoch, accumulated average loss = 0.238140 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.238209 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.237707 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.236526 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.236696 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.236499 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.236138 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.236357 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.236538 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.236626 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_380_epoch\n** End of epoch, accumulated average loss = 0.237421 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.236733 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.236868 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.234702 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.235111 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.234675 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.234293 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.234741 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.237081 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.234799 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_390_epoch\n** End of epoch, accumulated average loss = 0.234016 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.233672 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.233414 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.232694 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.233695 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.234463 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.232075 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.232476 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.233178 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.233609 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_400_epoch\n** End of epoch, accumulated average loss = 0.232709 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.231388 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.231344 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.232658 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.232992 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.232790 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.231196 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.230491 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.231021 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.229604 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_410_epoch\n** End of epoch, accumulated average loss = 0.230188 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.230408 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.230061 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.230006 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.230040 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.230377 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.229178 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.229717 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.229695 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.229804 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_420_epoch\n** End of epoch, accumulated average loss = 0.228404 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.229028 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.228344 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.228431 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.227368 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.227847 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.227145 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.227643 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.226405 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.227605 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_430_epoch\n** End of epoch, accumulated average loss = 0.226971 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.226167 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.226082 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.226872 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.226871 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.226242 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.226200 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.225500 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.225335 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.224986 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_440_epoch\n** End of epoch, accumulated average loss = 0.224504 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.224368 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.224521 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.223397 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.223889 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.224956 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.224489 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.223773 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.224165 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.222999 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_450_epoch\n** End of epoch, accumulated average loss = 0.223001 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.222100 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.223047 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.221866 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.221668 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.222790 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.222234 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.221630 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.223148 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.222055 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_460_epoch\n** End of epoch, accumulated average loss = 0.221901 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.221610 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.220448 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.220178 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.220401 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.220404 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.220400 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.219933 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.220240 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.219593 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_470_epoch\n** End of epoch, accumulated average loss = 0.219623 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.220007 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.218762 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.219135 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.218040 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.219205 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.218727 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.218399 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.218719 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.217876 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_480_epoch\n** End of epoch, accumulated average loss = 0.218066 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.218108 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.216197 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.216526 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.217129 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.216423 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.216839 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.216605 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.216200 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.216330 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_490_epoch\n** End of epoch, accumulated average loss = 0.215271 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.216122 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.215809 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.215903 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.214947 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.215466 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.215171 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.214913 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.215016 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.213839 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_500_epoch\n** End of epoch, accumulated average loss = 0.213910 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.213868 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.214558 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.214400 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.213853 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.213462 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.213827 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.213024 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.213120 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.212625 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_510_epoch\n** End of epoch, accumulated average loss = 0.212698 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.213272 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.212224 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.213279 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.212082 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.212571 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.211126 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.211405 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.211218 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.211384 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_520_epoch\n** End of epoch, accumulated average loss = 0.210866 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.210062 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.210011 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.209801 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.209972 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.210358 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.209828 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.210014 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.209215 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.209699 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_530_epoch\n** End of epoch, accumulated average loss = 0.209280 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.209025 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.209444 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.208545 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.208880 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.208096 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.208178 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.207870 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.208098 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.208127 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_540_epoch\n** End of epoch, accumulated average loss = 0.207119 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.207605 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.207245 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.207229 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.206487 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.206687 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.206666 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.205864 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.207021 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.206145 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_550_epoch\n** End of epoch, accumulated average loss = 0.205673 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.205447 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.205580 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.205798 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.205417 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.205146 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.204655 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.204550 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.204292 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.204639 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_560_epoch\n** End of epoch, accumulated average loss = 0.204401 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.204854 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.204008 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.203852 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.204200 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.204066 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.203775 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.203610 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.203745 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.203222 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_570_epoch\n** End of epoch, accumulated average loss = 0.202321 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.202915 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.202501 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.202758 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.202268 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.201840 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.202553 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.202033 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.201959 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.201688 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_580_epoch\n** End of epoch, accumulated average loss = 0.201478 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.201286 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.201395 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.201586 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.200597 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.200794 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.200640 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.200478 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.200485 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.200767 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_590_epoch\n** End of epoch, accumulated average loss = 0.201024 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.199939 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.200109 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.199312 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.199511 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.199807 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.199367 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.199718 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 0.199852 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 0.199564 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_600_epoch\n","output_type":"stream"}]},{"cell_type":"code","source":"allpreds = []\n\nfor part, (ids, x, y) in part2ixy.items():\n    print('\\nClassifying %s set with %d examples ...' % (part, len(x)))\n    st = time.time()\n    preds = classify(x, params)\n    print('%s set classified in %.2fs' % (part, time.time() - st))\n    count_of_values = list(map(len, preds))\n    assert np.all(np.array(count_of_values) == top_k)\n    #score(preds, y)\n    allpreds.extend(zip(ids, preds))\n\nsave_preds(allpreds, preds_fname='cc'+PREDS_FNAME)\nprint('\\nChecking saved predictions ...')\nscore_preds(preds_path='cc'+PREDS_FNAME, data_dir=TRANSLIT_PATH, parts=SCORED_PARTS)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T14:55:23.025941Z","iopub.execute_input":"2023-04-12T14:55:23.026347Z","iopub.status.idle":"2023-04-12T14:57:04.463631Z","shell.execute_reply.started":"2023-04-12T14:55:23.026310Z","shell.execute_reply":"2023-04-12T14:57:04.462533Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/527 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e233b7bb46d944009342c340f4d24df0"}},"metadata":{}},{"name":"stdout","text":"train set classified in 61.72s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b59c790d2ef4533a3a0a1f99cf4550d"}},"metadata":{}},{"name":"stdout","text":"dev set classified in 15.65s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7746a4179dab4876a37bdc6612f5ea32"}},"metadata":{}},{"name":"stdout","text":"train_small set classified in 1.17s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6be902a5cd5948f4a3113d1b4a6db95e"}},"metadata":{}},{"name":"stdout","text":"dev_small set classified in 1.19s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/165 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffb13b766ab549ca852f3cc94357a9a1"}},"metadata":{}},{"name":"stdout","text":"test set classified in 19.74s\nPredictions saved to ccpreds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.74\ndev set accuracy@1: 0.67\ntrain_small set accuracy@1: 0.74\ndev_small set accuracy@1: 0.68\nno labels for test set\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"{'train': {'acc@1': 0.7448918582911807},\n 'dev': {'acc@1': 0.6683623111381064},\n 'train_small': {'acc@1': 0.745},\n 'dev_small': {'acc@1': 0.684}}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Label smoothing","metadata":{"id":"7hMYmIO2tf8z"}},{"cell_type":"markdown","source":"We suggest to implement an additional regularization method - **label smoothing**. Now imagine that we have a prediction vector from probabilities at position t in the sequence of tokens for each token id from the vocabulary. CrossEntropy compares it with ground truth one-hot representation\n\n$$[0, ... 0, 1, 0, ..., 0].$$\n\nAnd now imagine that we are slightly \"smoothed\" the values in the ground truth vector and obtained\n\n$$[\\frac{\\alpha}{|V|}, ..., \\frac{\\alpha}{|V|}, 1(1-\\alpha)+\\frac{\\alpha}{|V|},  \\frac{\\alpha}{|V|}, ... \\frac{\\alpha}{|V|}],$$\n\nwhere $\\alpha$ - parameter from 0 to 1, $|V|$ - vocabulary size - number of components in the ground truth vector. The values ​​of this new vector are still summed to 1. Calculate the cross-entropy of our prediction vector and the new ground truth. Now, firstly, cross-entropy will never reach 0, and secondly, the result of the error function will require the model, as usual, to return the highest probability vector compared to other components of the probability vector for the correct token in the dictionary, but at the same time not too large, because as the value of this probability approaches 1, the value of the error function increases. For research on the use of label smoothing, see the [paper](https://arxiv.org/abs/1906.02629).\n    \nAccordingly, in order to embed label smoothing into the model, it is necessary to carry out the transformation described above on the ground truth vectors, as well as to implement the cross-entropy calculation, since the used `torch.nn.CrossEntropy` class is not quite suitable, since for the ground truth representation of `__call__` method takes the id of the correct token and builds a one-hot vector already inside. However, it is possible to implement what is required based on the internal implementation of this class [CrossEntropyLoss](https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#CrossEntropyLoss).\n    \n\nTest different values of $\\alpha$ (e.x, 0.05, 0.1, 0.2). Describe your experiments and results.\n","metadata":{"id":"setYzbjCtqZY"}},{"cell_type":"markdown","source":"```\n\nFor my experiments I tried suggested alphas: 0.05, 0.1 and 0.2. I ran them on best hyperparameters, which got on previous task. 0.2 and 0.1 smoothing parameters gave almost same results, so I tried them both on public leaderboeard. 0.2 gave me better result.\n\n```","metadata":{"id":"bL9V_9-7bVzw"}},{"cell_type":"code","source":"params = train(train_strings, train_transliterations, 0.1, 2e-3, 0.05)\nallpreds = []\n\nfor part, (ids, x, y) in part2ixy.items():\n    print('\\nClassifying %s set with %d examples ...' % (part, len(x)))\n    st = time.time()\n    preds = classify(x, params)\n    print('%s set classified in %.2fs' % (part, time.time() - st))\n    count_of_values = list(map(len, preds))\n    assert np.all(np.array(count_of_values) == top_k)\n    #score(preds, y)\n    allpreds.extend(zip(ids, preds))\n\nsave_preds(allpreds, preds_fname=PREDS_FNAME)\nprint('\\nChecking saved predictions ...')\nscore_preds(preds_path=PREDS_FNAME, data_dir=TRANSLIT_PATH, parts=SCORED_PARTS)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T11:43:09.911812Z","iopub.execute_input":"2023-04-08T11:43:09.912336Z","iopub.status.idle":"2023-04-08T11:44:53.522988Z","shell.execute_reply.started":"2023-04-08T11:43:09.912300Z","shell.execute_reply":"2023-04-08T11:44:53.521887Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 527/527 [01:03<00:00,  8.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"train set classified in 63.09s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 132/132 [00:15<00:00,  8.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev set classified in 15.90s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"train_small set classified in 1.16s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:01<00:00,  8.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"dev_small set classified in 1.15s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 165/165 [00:20<00:00,  8.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"test set classified in 20.34s\nPredictions saved to preds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.64\ndev set accuracy@1: 0.62\ntrain_small set accuracy@1: 0.64\ndev_small set accuracy@1: 0.64\nno labels for test set\n","output_type":"stream"},{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"{'train': {'acc@1': 0.6366362661453341},\n 'dev': {'acc@1': 0.6217447422367323},\n 'train_small': {'acc@1': 0.6425},\n 'dev_small': {'acc@1': 0.6415}}"},"metadata":{}}]},{"cell_type":"code","source":"params = train(train_strings, train_transliterations, 0.1, 2e-3, 0.1)\n\nallpreds = []\n\nfor part, (ids, x, y) in part2ixy.items():\n    print('\\nClassifying %s set with %d examples ...' % (part, len(x)))\n    st = time.time()\n    preds = classify(x, params)\n    print('%s set classified in %.2fs' % (part, time.time() - st))\n    count_of_values = list(map(len, preds))\n    assert np.all(np.array(count_of_values) == top_k)\n    #score(preds, y)\n    allpreds.extend(zip(ids, preds))\n\nsave_preds(allpreds, preds_fname=PREDS_FNAME)\nprint('\\nChecking saved predictions ...')\nscore_preds(preds_path=PREDS_FNAME, data_dir=TRANSLIT_PATH, parts=SCORED_PARTS)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T11:48:45.268578Z","iopub.execute_input":"2023-04-08T11:48:45.269504Z","iopub.status.idle":"2023-04-08T12:17:01.685131Z","shell.execute_reply.started":"2023-04-08T11:48:45.269453Z","shell.execute_reply":"2023-04-08T12:17:01.683956Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Using GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b1fa1eab5a24a6a897de38f74e68f02"}},"metadata":{}},{"name":"stdout","text":"** End of epoch, accumulated average loss = 4.144771 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.654272 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.804311 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.606924 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.504642 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.459740 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.429379 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.417199 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.408235 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.375768 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_10_epoch\n** End of epoch, accumulated average loss = 1.368155 **\n** Elapsed time: 0:00:17**\n** End of epoch, accumulated average loss = 1.352383 **\n** Elapsed time: 0:00:17**\n** End of epoch, accumulated average loss = 1.344887 **\n** Elapsed time: 0:00:17**\n** End of epoch, accumulated average loss = 1.340912 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.334439 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.325068 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.321968 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.318803 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.316458 **\n** Elapsed time: 0:00:17**\n** End of epoch, accumulated average loss = 1.307895 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_20_epoch\n** End of epoch, accumulated average loss = 1.304830 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.301474 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.299089 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.297075 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.292844 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.290839 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.288168 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.285151 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.284726 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.281168 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_30_epoch\n** End of epoch, accumulated average loss = 1.280174 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.278318 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.276135 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.274716 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.273788 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.271777 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.270407 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.268330 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.267398 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.265676 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_40_epoch\n** End of epoch, accumulated average loss = 1.264709 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.262816 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.262848 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.260937 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.258440 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.257805 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.255920 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.256229 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.254345 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.253910 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_50_epoch\n** End of epoch, accumulated average loss = 1.252688 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.250786 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.249295 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.249059 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.247405 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.246714 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.245960 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.245080 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.243367 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.242791 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_60_epoch\n** End of epoch, accumulated average loss = 1.241097 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.241087 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.239743 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.237754 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.238193 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.237008 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.235548 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.234461 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.233996 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.233402 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_70_epoch\n** End of epoch, accumulated average loss = 1.232520 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.231744 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.230688 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.228977 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.228754 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.227744 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.226920 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.225700 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.225725 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.224755 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_80_epoch\n** End of epoch, accumulated average loss = 1.223915 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.222876 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.221627 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.221277 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.220394 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.219718 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.219307 **\n** Elapsed time: 0:00:17**\n** End of epoch, accumulated average loss = 1.217964 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.217480 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.216687 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_90_epoch\n** End of epoch, accumulated average loss = 1.215961 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.215022 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.214831 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.214181 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.213568 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.212451 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.211999 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.211967 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.211136 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.210479 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_100_epoch\n\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/527 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a988e972ea434dc49ce6f47b9f62361f"}},"metadata":{}},{"name":"stdout","text":"train set classified in 65.01s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8b44adae220461bb2c508090c881753"}},"metadata":{}},{"name":"stdout","text":"dev set classified in 16.09s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4707453151d41d4867aea896de7ba40"}},"metadata":{}},{"name":"stdout","text":"train_small set classified in 1.23s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d9f0278965a482cbca6e28ea37f5144"}},"metadata":{}},{"name":"stdout","text":"dev_small set classified in 1.22s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/165 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"263720e01ef3403b99b7d03bc5acce06"}},"metadata":{}},{"name":"stdout","text":"test set classified in 20.51s\nPredictions saved to preds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.70\ndev set accuracy@1: 0.66\ntrain_small set accuracy@1: 0.69\ndev_small set accuracy@1: 0.68\nno labels for test set\n","output_type":"stream"},{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"{'train': {'acc@1': 0.7024228677719676},\n 'dev': {'acc@1': 0.6631235289651507},\n 'train_small': {'acc@1': 0.695},\n 'dev_small': {'acc@1': 0.6755}}"},"metadata":{}}]},{"cell_type":"code","source":"params = train(train_strings, train_transliterations, 0.1, 2e-3, 0.2)\n\nallpreds = []\n\nfor part, (ids, x, y) in part2ixy.items():\n    print('\\nClassifying %s set with %d examples ...' % (part, len(x)))\n    st = time.time()\n    preds = classify(x, params)\n    print('%s set classified in %.2fs' % (part, time.time() - st))\n    count_of_values = list(map(len, preds))\n    assert np.all(np.array(count_of_values) == top_k)\n    #score(preds, y)\n    allpreds.extend(zip(ids, preds))\n\nsave_preds(allpreds, preds_fname='0.2sm'+PREDS_FNAME)\nprint('\\nChecking saved predictions ...')\nscore_preds(preds_path='0.2sm'+PREDS_FNAME, data_dir=TRANSLIT_PATH, parts=SCORED_PARTS)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T12:19:34.834570Z","iopub.execute_input":"2023-04-08T12:19:34.835535Z","iopub.status.idle":"2023-04-08T12:47:51.923469Z","shell.execute_reply.started":"2023-04-08T12:19:34.835480Z","shell.execute_reply":"2023-04-08T12:47:51.922422Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Using GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25d31c9b55b541edb50d509d11d69b31"}},"metadata":{}},{"name":"stdout","text":"** End of epoch, accumulated average loss = 4.505634 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 3.218219 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.512064 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.352614 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.248511 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.203865 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.172396 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.155503 **\n** Elapsed time: 0:00:17**\n** End of epoch, accumulated average loss = 2.142074 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.136194 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_10_epoch\n** End of epoch, accumulated average loss = 2.123255 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.111490 **\n** Elapsed time: 0:00:17**\n** End of epoch, accumulated average loss = 2.105017 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.096808 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.091880 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.089486 **\n** Elapsed time: 0:00:17**\n** End of epoch, accumulated average loss = 2.080093 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.079422 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.074614 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.070941 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_20_epoch\n** End of epoch, accumulated average loss = 2.069049 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.064895 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.065511 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.061532 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.057624 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.057027 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.053755 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.052296 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.052907 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.047738 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_30_epoch\n** End of epoch, accumulated average loss = 2.048088 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.044917 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.044577 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.042090 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.041686 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.039924 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.039969 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.037036 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.035239 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.034205 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_40_epoch\n** End of epoch, accumulated average loss = 2.034711 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.032752 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.031863 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.030371 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.029446 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.028894 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.027923 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.025768 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.025371 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.024199 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_50_epoch\n** End of epoch, accumulated average loss = 2.022705 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.022175 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.021086 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.019646 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.020205 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.019155 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.017809 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.016736 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.015589 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.015547 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_60_epoch\n** End of epoch, accumulated average loss = 2.013570 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.013371 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.012854 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.012553 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.011194 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.010031 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.008898 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.008243 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.008194 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.006870 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_70_epoch\n** End of epoch, accumulated average loss = 2.006144 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.005045 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.005207 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.003713 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.003113 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.002740 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.001699 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.001238 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.000173 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.999825 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_80_epoch\n** End of epoch, accumulated average loss = 1.998850 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.998312 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.997340 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.996970 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.996108 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.995226 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.994499 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.994011 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.993578 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.992377 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_90_epoch\n** End of epoch, accumulated average loss = 1.992281 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.991410 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.990874 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.990454 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.989885 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.989506 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.988944 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.988292 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.988067 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.987828 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_100_epoch\n\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/527 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9e229ae56494aa486216d8500456568"}},"metadata":{}},{"name":"stdout","text":"train set classified in 64.33s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11239c994b0f49769d808aee859bd66a"}},"metadata":{}},{"name":"stdout","text":"dev set classified in 16.47s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"672c07cbb39c4bcb8b8f8437061dfa46"}},"metadata":{}},{"name":"stdout","text":"train_small set classified in 1.20s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90beaf3e8fae4255859dbbab5964aae2"}},"metadata":{}},{"name":"stdout","text":"dev_small set classified in 1.21s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/165 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2442cb4c5034112b117d072769e15a9"}},"metadata":{}},{"name":"stdout","text":"test set classified in 20.43s\nPredictions saved to 0.2smpreds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.70\ndev set accuracy@1: 0.66\ntrain_small set accuracy@1: 0.70\ndev_small set accuracy@1: 0.67\nno labels for test set\n","output_type":"stream"},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"{'train': {'acc@1': 0.6969090167123781},\n 'dev': {'acc@1': 0.6579227089818541},\n 'train_small': {'acc@1': 0.7025},\n 'dev_small': {'acc@1': 0.673}}"},"metadata":{}}]},{"cell_type":"code","source":"params = train(train_strings, train_transliterations, 0.1, 2e-3, 0.2, 600)\n\nallpreds = []\n\nfor part, (ids, x, y) in part2ixy.items():\n    print('\\nClassifying %s set with %d examples ...' % (part, len(x)))\n    st = time.time()\n    preds = classify(x, params)\n    print('%s set classified in %.2fs' % (part, time.time() - st))\n    count_of_values = list(map(len, preds))\n    assert np.all(np.array(count_of_values) == top_k)\n    #score(preds, y)\n    allpreds.extend(zip(ids, preds))\n\nsave_preds(allpreds, preds_fname=PREDS_FNAME)\nprint('\\nChecking saved predictions ...')\nscore_preds(preds_path=PREDS_FNAME, data_dir=TRANSLIT_PATH, parts=SCORED_PARTS)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T15:13:01.529045Z","iopub.execute_input":"2023-04-12T15:13:01.529420Z","iopub.status.idle":"2023-04-12T17:47:13.553101Z","shell.execute_reply.started":"2023-04-12T15:13:01.529389Z","shell.execute_reply":"2023-04-12T17:47:13.552020Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Using GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/600 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6911afd8cf64986bf3f3cfad157f977"}},"metadata":{}},{"name":"stdout","text":"** End of epoch, accumulated average loss = 4.989224 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 4.061223 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 3.806479 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 3.145925 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.674329 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.524342 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.421709 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.341439 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.281719 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.243578 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_10_epoch\n** End of epoch, accumulated average loss = 2.213779 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.193614 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.173992 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.158387 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.143720 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.131715 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.119423 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.109866 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.101535 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.096481 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_20_epoch\n** End of epoch, accumulated average loss = 2.091105 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.086557 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.080928 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.077758 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.074619 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.071611 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.069486 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.068537 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.065597 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.063924 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_30_epoch\n** End of epoch, accumulated average loss = 2.062458 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.060611 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.059796 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.059330 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.059049 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.056275 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.055651 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.055249 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.054753 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.054392 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_40_epoch\n** End of epoch, accumulated average loss = 2.051560 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.054901 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.052466 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.051996 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.051421 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.051538 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.050274 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.050719 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.052852 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.050108 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_50_epoch\n** End of epoch, accumulated average loss = 2.050478 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.051636 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.048341 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.049162 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.049707 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.050413 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.049683 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.049231 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.054766 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.048316 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_60_epoch\n** End of epoch, accumulated average loss = 2.047412 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.048554 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.048923 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.045246 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.044396 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.046902 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.043817 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.044951 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.043225 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.044707 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_70_epoch\n** End of epoch, accumulated average loss = 2.040479 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.041402 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.042887 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.040496 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.043711 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.043078 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.038226 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.037145 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.038920 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.036817 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_80_epoch\n** End of epoch, accumulated average loss = 2.037288 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.038712 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.035862 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.036665 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.036817 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.036090 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.034704 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.035266 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.034846 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.033625 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_90_epoch\n** End of epoch, accumulated average loss = 2.032877 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.034389 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.033256 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.031695 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.033809 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.032198 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.031112 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.030562 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.031636 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.031335 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_100_epoch\n** End of epoch, accumulated average loss = 2.030238 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.029555 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.029313 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.030406 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.029432 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.028546 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.028273 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.029791 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.028749 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.028965 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_110_epoch\n** End of epoch, accumulated average loss = 2.028393 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.027480 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.027200 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.026822 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.028577 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.027857 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.025984 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.026620 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.027840 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.025647 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_120_epoch\n** End of epoch, accumulated average loss = 2.025951 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.025313 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.025626 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.024679 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.024400 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.025675 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.025651 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.024541 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.024418 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.024873 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_130_epoch\n** End of epoch, accumulated average loss = 2.023128 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.024615 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.023450 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.024046 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.022360 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.022876 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.022691 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.023648 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.022276 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.022498 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_140_epoch\n** End of epoch, accumulated average loss = 2.021710 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.022209 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.021553 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.021429 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.022037 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.021909 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.020782 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.021358 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.020925 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.019775 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_150_epoch\n** End of epoch, accumulated average loss = 2.020301 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.019876 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.020057 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.019885 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.019379 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.018460 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.018625 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.018707 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.019307 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.018410 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_160_epoch\n** End of epoch, accumulated average loss = 2.017433 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.018748 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.017702 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.017828 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.019161 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.017965 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.017010 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.017507 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.016929 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.016778 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_170_epoch\n** End of epoch, accumulated average loss = 2.018416 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.016531 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.017017 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.016679 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.016316 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.016071 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.016186 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.016422 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.016014 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.015682 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_180_epoch\n** End of epoch, accumulated average loss = 2.015507 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.015031 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.015062 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.015783 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.014653 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.014459 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.015156 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.016264 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.014711 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.013352 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_190_epoch\n** End of epoch, accumulated average loss = 2.013410 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.013360 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.013835 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.013993 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.015092 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.013099 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.013039 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.013383 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.012521 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.012293 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_200_epoch\n** End of epoch, accumulated average loss = 2.012153 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.012298 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.012276 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.010872 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.012476 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.012146 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.010999 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.012568 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.011381 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.011419 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_210_epoch\n** End of epoch, accumulated average loss = 2.011280 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.010881 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.011742 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.010880 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.011243 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.010520 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.010201 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.010359 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.009590 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.010451 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_220_epoch\n** End of epoch, accumulated average loss = 2.009777 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.010735 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.009278 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.010074 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.009209 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.008531 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.009341 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.007900 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.009127 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.008287 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_230_epoch\n** End of epoch, accumulated average loss = 2.008368 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.007963 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.007404 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.007702 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.008655 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.007926 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.007310 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.007578 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.007129 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.006836 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_240_epoch\n** End of epoch, accumulated average loss = 2.006552 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.006639 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.007144 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.006981 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.006429 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.007075 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.007218 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.006255 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.005627 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.005649 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_250_epoch\n** End of epoch, accumulated average loss = 2.005360 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.005255 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.005066 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.005327 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.005146 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.004931 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.005179 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.004836 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.005142 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.005261 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_260_epoch\n** End of epoch, accumulated average loss = 2.004750 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.003881 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.004145 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.004339 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.003706 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.003567 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.003259 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.004512 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 2.003955 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.003407 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_270_epoch\n** End of epoch, accumulated average loss = 2.003984 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.003144 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.002685 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.002750 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.002019 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.002824 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.001859 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.003170 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.002242 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.001642 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_280_epoch\n** End of epoch, accumulated average loss = 2.001465 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.000900 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.001798 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.001761 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.001562 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.000958 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.000905 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.001291 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.000497 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.001042 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_290_epoch\n** End of epoch, accumulated average loss = 2.001105 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.000547 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.001978 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.999985 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.000180 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.999066 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.999876 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.000159 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.000039 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.000245 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_300_epoch\n** End of epoch, accumulated average loss = 2.000262 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.999933 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.998694 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.998832 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.999357 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.999446 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.997874 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.998258 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.998530 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.997868 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_310_epoch\n** End of epoch, accumulated average loss = 1.998131 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.998433 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.998254 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.997633 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.997134 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.997629 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.996753 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.997169 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.997187 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.996996 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_320_epoch\n** End of epoch, accumulated average loss = 1.997297 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.996630 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.996316 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.996364 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.996724 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.996716 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.996404 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.996122 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.996210 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.995701 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_330_epoch\n** End of epoch, accumulated average loss = 1.995847 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.995500 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.996032 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.995772 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.995165 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.995195 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.994943 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.994270 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.994241 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.994092 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_340_epoch\n** End of epoch, accumulated average loss = 1.994575 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.994950 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.994093 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.994288 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.994123 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.993567 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.993535 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.994071 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.993396 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.993255 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_350_epoch\n** End of epoch, accumulated average loss = 1.993221 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.993196 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.993120 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.992388 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.992568 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.992069 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.992025 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.991946 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.992480 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.992542 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_360_epoch\n** End of epoch, accumulated average loss = 1.992293 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.992196 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.991432 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.991685 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.991250 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.991260 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.990851 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.991144 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.991364 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.991098 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_370_epoch\n** End of epoch, accumulated average loss = 1.991446 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.990147 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.991355 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.990740 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.990225 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.989804 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.989626 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.989723 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.990186 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.989639 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_380_epoch\n** End of epoch, accumulated average loss = 1.989347 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.989554 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.988822 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.989084 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.989170 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.989048 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.989395 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.989142 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.988198 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.988213 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_390_epoch\n** End of epoch, accumulated average loss = 1.988377 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.988670 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.987358 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.988234 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.988311 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.987596 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.987597 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.987675 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.987225 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.987338 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_400_epoch\n** End of epoch, accumulated average loss = 1.987554 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.987533 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.986876 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.986872 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.986853 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.986623 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.986734 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.987056 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.985940 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.986051 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_410_epoch\n** End of epoch, accumulated average loss = 1.986083 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.985795 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.985326 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.985546 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.985618 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.985963 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.985153 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.985223 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.985405 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.984893 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_420_epoch\n** End of epoch, accumulated average loss = 1.985184 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.984704 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.984679 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.984614 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.984958 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.984048 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.983604 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.983997 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.984551 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.984017 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_430_epoch\n** End of epoch, accumulated average loss = 1.983875 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.983132 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.983474 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.983472 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.983140 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.983707 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.982652 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.982623 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.982936 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.982822 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_440_epoch\n** End of epoch, accumulated average loss = 1.982639 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.982217 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.982344 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.982617 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.981983 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.981944 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.981678 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.981392 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.981700 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.981853 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_450_epoch\n** End of epoch, accumulated average loss = 1.981730 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.981093 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.980828 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.981251 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.981595 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.980791 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.980796 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.980502 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.980524 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.980381 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_460_epoch\n** End of epoch, accumulated average loss = 1.980848 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.980308 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.979822 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.979942 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.980300 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.980313 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.979763 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.979416 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.979059 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.979330 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_470_epoch\n** End of epoch, accumulated average loss = 1.979091 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.978908 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.978659 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.978364 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.978143 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.978595 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.978380 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.978624 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.978383 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.978701 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_480_epoch\n** End of epoch, accumulated average loss = 1.977924 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.977929 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.978026 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.977501 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.977444 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.977143 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.977755 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.976864 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.977271 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.977284 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_490_epoch\n** End of epoch, accumulated average loss = 1.976547 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.976494 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.976613 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.976503 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.976744 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.976005 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.976441 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.975978 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.975896 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.975862 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_500_epoch\n** End of epoch, accumulated average loss = 1.975962 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.976033 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.975334 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.975732 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.975883 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.975277 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.975033 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.974759 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.975023 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.974569 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_510_epoch\n** End of epoch, accumulated average loss = 1.974446 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.974855 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.974867 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.974285 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.974086 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.974076 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.974056 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.974179 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.973787 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.973668 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_520_epoch\n** End of epoch, accumulated average loss = 1.973359 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.974034 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.973038 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.972603 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.973043 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.972894 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.973091 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.972926 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.972767 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.973199 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_530_epoch\n** End of epoch, accumulated average loss = 1.972759 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.972049 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.972324 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.972274 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.972172 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.971987 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.972061 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.971539 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.971510 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.971818 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_540_epoch\n** End of epoch, accumulated average loss = 1.971172 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.971291 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.971357 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.971123 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.971283 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.970743 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.970765 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.970583 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.970288 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.970905 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_550_epoch\n** End of epoch, accumulated average loss = 1.970020 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.970802 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.970226 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.970178 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.969958 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.970034 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.970016 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.969290 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.969356 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.969839 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_560_epoch\n** End of epoch, accumulated average loss = 1.969349 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.969396 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.969718 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.969295 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.968824 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.968862 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.968707 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.968616 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.969342 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.968331 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_570_epoch\n** End of epoch, accumulated average loss = 1.968663 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.968753 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.968433 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.968419 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.968151 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.967658 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.967906 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.968275 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.968003 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.967552 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_580_epoch\n** End of epoch, accumulated average loss = 1.967607 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.967445 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.967539 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.967376 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.967509 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.967370 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.967399 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.966855 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.967164 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.966974 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_590_epoch\n** End of epoch, accumulated average loss = 1.966603 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.966886 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.966951 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.966614 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.966872 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.966176 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.966292 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.966364 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.966128 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.966595 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_600_epoch\n\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/527 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30304725d0e54c0090a2db76e9e1becf"}},"metadata":{}},{"name":"stdout","text":"train set classified in 62.43s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ba19cc81b8e4a84b5313bfb6dcf6de7"}},"metadata":{}},{"name":"stdout","text":"dev set classified in 15.53s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93ade249c1274799980b9f844f5ff7ff"}},"metadata":{}},{"name":"stdout","text":"train_small set classified in 1.24s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46aaa71c6b5442e1a76714f75dfc79f5"}},"metadata":{}},{"name":"stdout","text":"dev_small set classified in 1.23s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/165 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa4abe6f408840a1898b79a5ff03012c"}},"metadata":{}},{"name":"stdout","text":"test set classified in 19.77s\nPredictions saved to preds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.74\ndev set accuracy@1: 0.67\ntrain_small set accuracy@1: 0.75\ndev_small set accuracy@1: 0.68\nno labels for test set\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"{'train': {'acc@1': 0.7419593626329825},\n 'dev': {'acc@1': 0.6711335509832207},\n 'train_small': {'acc@1': 0.7495},\n 'dev_small': {'acc@1': 0.6815}}"},"metadata":{}}]},{"cell_type":"code","source":"params = train(train_strings, train_transliterations, 0.1, 2e-3, 0.1, 300)\n\nallpreds = []\n\nfor part, (ids, x, y) in part2ixy.items():\n    print('\\nClassifying %s set with %d examples ...' % (part, len(x)))\n    st = time.time()\n    preds = classify(x, params)\n    print('%s set classified in %.2fs' % (part, time.time() - st))\n    count_of_values = list(map(len, preds))\n    assert np.all(np.array(count_of_values) == top_k)\n    #score(preds, y)\n    allpreds.extend(zip(ids, preds))\n\nsave_preds(allpreds, preds_fname=PREDS_FNAME)\nprint('\\nChecking saved predictions ...')\nscore_preds(preds_path=PREDS_FNAME, data_dir=TRANSLIT_PATH, parts=SCORED_PARTS)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T17:58:23.822780Z","iopub.execute_input":"2023-04-12T17:58:23.823536Z","iopub.status.idle":"2023-04-12T19:16:19.936166Z","shell.execute_reply.started":"2023-04-12T17:58:23.823484Z","shell.execute_reply":"2023-04-12T19:16:19.934835Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Using GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a810c23a72b43ef8523fc8f1311a69b"}},"metadata":{}},{"name":"stdout","text":"** End of epoch, accumulated average loss = 4.351293 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 3.382729 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 2.360794 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.879261 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.710870 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.597615 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.524089 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.480251 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.449179 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.427254 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_10_epoch\n** End of epoch, accumulated average loss = 1.405055 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.387667 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.370868 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.360554 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.351754 **\n** Elapsed time: 0:00:17**\n** End of epoch, accumulated average loss = 1.345136 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.337120 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.331193 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.326640 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.323689 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_20_epoch\n** End of epoch, accumulated average loss = 1.322040 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.318621 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.319289 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.314986 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.310888 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.309827 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.310463 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.307606 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.306957 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.307317 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_30_epoch\n** End of epoch, accumulated average loss = 1.304909 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.302931 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.299684 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.307556 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.296663 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.292321 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.291220 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.289559 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.289570 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.287838 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_40_epoch\n** End of epoch, accumulated average loss = 1.284535 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.285321 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.284662 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.283640 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.279705 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.279820 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.278502 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.278014 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.278783 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.274012 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_50_epoch\n** End of epoch, accumulated average loss = 1.274564 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.273952 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.274182 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.273640 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.270843 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.270598 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.270506 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.269052 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.268802 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.268386 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_60_epoch\n** End of epoch, accumulated average loss = 1.267367 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.266713 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.267926 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.264204 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.264758 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.264379 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.263011 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.263011 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.264595 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.262466 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_70_epoch\n** End of epoch, accumulated average loss = 1.262292 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.260039 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.260445 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.259956 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.258879 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.258590 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.258570 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.260149 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.257265 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.256575 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_80_epoch\n** End of epoch, accumulated average loss = 1.256189 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.254283 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.255468 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.255343 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.255374 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.253978 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.254894 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.255047 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.251490 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.252266 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_90_epoch\n** End of epoch, accumulated average loss = 1.252422 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.250966 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.252616 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.251432 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.250440 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.250088 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.250740 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.249941 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.248929 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.248928 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_100_epoch\n** End of epoch, accumulated average loss = 1.248277 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.248155 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.247395 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.247890 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.248115 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.247013 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.245956 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.245175 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.245449 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.246367 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_110_epoch\n** End of epoch, accumulated average loss = 1.245610 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.244557 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.243935 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.244105 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.242929 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.242178 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.243061 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.242729 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.241861 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.243993 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_120_epoch\n** End of epoch, accumulated average loss = 1.240380 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.240352 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.240447 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.240754 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.240768 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.239914 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.239803 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.239035 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.238612 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.238742 **\n** Elapsed time: 0:00:16**\nSaved checkpoint to ./model/cpkt_130_epoch\n** End of epoch, accumulated average loss = 1.237502 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.237738 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.237121 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.237356 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.237305 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.236254 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.237326 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.236211 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.237046 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.236191 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_140_epoch\n** End of epoch, accumulated average loss = 1.235215 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.234533 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.233797 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.235161 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.233404 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.233659 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.232527 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.232918 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.232651 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.232277 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_150_epoch\n** End of epoch, accumulated average loss = 1.232261 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.231639 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.231694 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.231049 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.231539 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.230872 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.230590 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.230653 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.229946 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.229159 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_160_epoch\n** End of epoch, accumulated average loss = 1.229201 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.228826 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.228971 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.227728 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.228193 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.227590 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.227117 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.227455 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.226466 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.226302 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_170_epoch\n** End of epoch, accumulated average loss = 1.226376 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.225800 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.224998 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.225333 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.224747 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.225173 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.224565 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.223919 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.224170 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.223793 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_180_epoch\n** End of epoch, accumulated average loss = 1.223407 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.222691 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.222172 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.222084 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.222606 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.222233 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.221705 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.221187 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.220632 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.220910 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_190_epoch\n** End of epoch, accumulated average loss = 1.220385 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.220165 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.220462 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.219025 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.219167 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.218788 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.219434 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.219110 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.218492 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.218009 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_200_epoch\n** End of epoch, accumulated average loss = 1.217832 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.216990 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.217359 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.216641 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.216293 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.216060 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.216034 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.215713 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.215779 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.215676 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_210_epoch\n** End of epoch, accumulated average loss = 1.214811 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.214619 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.214312 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.213897 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.213914 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.213417 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.213057 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.213163 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.212971 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.212169 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_220_epoch\n** End of epoch, accumulated average loss = 1.211897 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.211669 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.211825 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.211258 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.211962 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.210711 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.210722 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.209891 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.209888 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.209803 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_230_epoch\n** End of epoch, accumulated average loss = 1.209745 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.209154 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.208505 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.208890 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.208268 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.208613 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.208423 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.207347 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.207413 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.206495 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_240_epoch\n** End of epoch, accumulated average loss = 1.206673 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.206333 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.206167 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.206180 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.206064 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.205434 **\n** Elapsed time: 0:00:16**\n** End of epoch, accumulated average loss = 1.205038 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.204873 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.205056 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.204371 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_250_epoch\n** End of epoch, accumulated average loss = 1.203884 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.203775 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.203538 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.203144 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.203257 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.202703 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.202404 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.203036 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.201496 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.202274 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_260_epoch\n** End of epoch, accumulated average loss = 1.201278 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.201418 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.201071 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.201042 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.200659 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.200183 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.199939 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.199778 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.199406 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.199788 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_270_epoch\n** End of epoch, accumulated average loss = 1.198626 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.198872 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.199064 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.197970 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.198372 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.198562 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.197921 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.197128 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.197596 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.197236 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_280_epoch\n** End of epoch, accumulated average loss = 1.197065 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.196714 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.196617 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.196148 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.196030 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.195278 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.195349 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.195287 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.195139 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.195167 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_290_epoch\n** End of epoch, accumulated average loss = 1.194481 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.194873 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.194049 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.194209 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.194402 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.193308 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.193882 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.194033 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.193571 **\n** Elapsed time: 0:00:15**\n** End of epoch, accumulated average loss = 1.193666 **\n** Elapsed time: 0:00:15**\nSaved checkpoint to ./model/cpkt_300_epoch\n\nClassifying train set with 105371 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/527 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0b6c9f818754e218994bff9d7bbd06f"}},"metadata":{}},{"name":"stdout","text":"train set classified in 62.24s\n\nClassifying dev set with 26342 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/132 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d654ce93621d495fb3255557f15e0a63"}},"metadata":{}},{"name":"stdout","text":"dev set classified in 16.03s\n\nClassifying train_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"233b9cf3a2c3469989a935e8352543b7"}},"metadata":{}},{"name":"stdout","text":"train_small set classified in 1.20s\n\nClassifying dev_small set with 2000 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7eb95ba54f141c28bdfd52290215fe7"}},"metadata":{}},{"name":"stdout","text":"dev_small set classified in 1.21s\n\nClassifying test set with 32926 examples ...\nUsing GPU device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/165 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a3516370f264682866bd0173f2033a0"}},"metadata":{}},{"name":"stdout","text":"test set classified in 19.22s\nPredictions saved to preds_translit.tsv\n\nChecking saved predictions ...\ntrain set accuracy@1: 0.73\ndev set accuracy@1: 0.67\ntrain_small set accuracy@1: 0.74\ndev_small set accuracy@1: 0.68\nno labels for test set\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"{'train': {'acc@1': 0.7306089910886296},\n 'dev': {'acc@1': 0.6691215549312884},\n 'train_small': {'acc@1': 0.736},\n 'dev_small': {'acc@1': 0.6765}}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}